{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.regression import *\n",
    "\n",
    "# W_LEV_AVG\t= ค่าระดับน้ำทะเล หน่วยเมตร\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"data_preprocess/raw_data/dmr_tidal-level-phuket-tidegauge-2013_2023.csv\")\n",
    "# ลบช่องว่างเกินออก (กันกรณีมี space แปลก ๆ)\n",
    "df[\"DATE\"] = df[\"DATE\"].str.strip()\n",
    "\n",
    "# เติมเลข 0 ให้ชั่วโมงหลักเดียว และเติม \":00\" ถ้าขาดวินาที\n",
    "df[\"DATE\"] = df[\"DATE\"].str.replace(r\"(\\d{1,2}/\\d{1,2}/\\d{4}) (\\d{1}):(\\d{2})$\", r\"\\1 0\\2:\\3:00\", regex=True)\n",
    "df[\"DATE\"] = df[\"DATE\"].str.replace(r\"(\\d{1,2}/\\d{1,2}/\\d{4}) (\\d{2}:\\d{2})$\", r\"\\1 \\2:00\", regex=True)\n",
    "\n",
    "# แปลงเป็น datetime โดยกำหนด dayfirst=True\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format=\"%d/%m/%Y %H:%M:%S\", dayfirst=True)\n",
    "df.set_index('DATE', inplace=True)\n",
    "df['dayofweek'] = df.index.dayofweek\n",
    "df['month'] = df.index.month\n",
    "df['day'] = df.index.day\n",
    "df['hour'] = df.index.hour\n",
    "\n",
    "df = df.drop(columns=[\"TW_ID\", \"TW_NAME\", \"UTM_E\", 'UTM_N'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01 07:00:00</th>\n",
       "      <td>0.4129</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 07:10:00</th>\n",
       "      <td>0.4528</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 07:20:00</th>\n",
       "      <td>0.4901</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 07:30:00</th>\n",
       "      <td>0.5079</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 07:40:00</th>\n",
       "      <td>0.5468</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:10:00</th>\n",
       "      <td>0.3508</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:20:00</th>\n",
       "      <td>0.4242</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:30:00</th>\n",
       "      <td>0.4790</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:40:00</th>\n",
       "      <td>0.5506</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:50:00</th>\n",
       "      <td>0.5865</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404878 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     W_LEV_AVG  dayofweek  month  day  hour\n",
       "DATE                                                       \n",
       "2013-10-01 07:00:00     0.4129          1     10    1     7\n",
       "2013-10-01 07:10:00     0.4528          1     10    1     7\n",
       "2013-10-01 07:20:00     0.4901          1     10    1     7\n",
       "2013-10-01 07:30:00     0.5079          1     10    1     7\n",
       "2013-10-01 07:40:00     0.5468          1     10    1     7\n",
       "...                        ...        ...    ...  ...   ...\n",
       "2023-12-31 23:10:00     0.3508          6     12   31    23\n",
       "2023-12-31 23:20:00     0.4242          6     12   31    23\n",
       "2023-12-31 23:30:00     0.4790          6     12   31    23\n",
       "2023-12-31 23:40:00     0.5506          6     12   31    23\n",
       "2023-12-31 23:50:00     0.5865          6     12   31    23\n",
       "\n",
       "[404878 rows x 5 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1 = df['W_LEV_AVG'].quantile(0.25)\n",
    "Q3 = df['W_LEV_AVG'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[(df['W_LEV_AVG'] >= Q1 - 1.5 * IQR) & (df['W_LEV_AVG'] <= Q3 + 1.5 * IQR)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ephem\n",
    "# ฟังก์ชันหาข้างขึ้นข้างแรม\n",
    "def get_moon_phase(dt):\n",
    "    moon_phase = ephem.Moon(dt).phase  # คำนวณเฟสของดวงจันทร์\n",
    "    return round(moon_phase)  # ปัดค่า phase ให้เป็นจำนวนเต็ม (0-29)\n",
    "\n",
    "# คำนวณข้างขึ้นข้างแรม และเพิ่มเป็นคอลัมน์ใหม่\n",
    "df[\"moon_phase\"] = df.index.to_series().apply(get_moon_phase)\n",
    "\n",
    "# เพิ่มคอลัมน์ full_moon_days (ขึ้น 15 ค่ำ) และ dark_moon_days (แรม 15 ค่ำ)\n",
    "df[\"full_moon_days\"] = (df[\"moon_phase\"] == 15).astype(int) #(ขึ้น 15 ค่ำ)\n",
    "df[\"dark_moon_days\"] = (df[\"moon_phase\"] == 29).astype(int) #(แรม 15 ค่ำ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>moon_phase</th>\n",
       "      <th>full_moon_days</th>\n",
       "      <th>dark_moon_days</th>\n",
       "      <th>W_LEV_AVG_lag_1</th>\n",
       "      <th>W_LEV_AVG_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>W_LEV_AVG_lag_9</th>\n",
       "      <th>W_LEV_AVG_lag_10</th>\n",
       "      <th>W_LEV_AVG_lag_11</th>\n",
       "      <th>W_LEV_AVG_lag_12</th>\n",
       "      <th>W_LEV_AVG_lag_13</th>\n",
       "      <th>W_LEV_AVG_lag_14</th>\n",
       "      <th>W_LEV_AVG_lag_15</th>\n",
       "      <th>W_LEV_AVG_lag_16</th>\n",
       "      <th>W_LEV_AVG_lag_17</th>\n",
       "      <th>W_LEV_AVG_lag_18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:00:00</th>\n",
       "      <td>-0.6634</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5485</td>\n",
       "      <td>-0.4397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>0.8538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:10:00</th>\n",
       "      <td>-0.7622</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.6634</td>\n",
       "      <td>-0.5485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>0.8169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:20:00</th>\n",
       "      <td>-0.8795</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7622</td>\n",
       "      <td>-0.6634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:30:00</th>\n",
       "      <td>-0.9905</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8795</td>\n",
       "      <td>-0.7622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:40:00</th>\n",
       "      <td>-1.0927</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9905</td>\n",
       "      <td>-0.8795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1052</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:10:00</th>\n",
       "      <td>0.3508</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3465</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>-0.7966</td>\n",
       "      <td>-0.8627</td>\n",
       "      <td>-0.9220</td>\n",
       "      <td>-0.9874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:20:00</th>\n",
       "      <td>0.4242</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2573</td>\n",
       "      <td>-0.3465</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>-0.7966</td>\n",
       "      <td>-0.8627</td>\n",
       "      <td>-0.9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:30:00</th>\n",
       "      <td>0.4790</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1770</td>\n",
       "      <td>-0.2573</td>\n",
       "      <td>-0.3465</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>-0.7966</td>\n",
       "      <td>-0.8627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:40:00</th>\n",
       "      <td>0.5506</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0942</td>\n",
       "      <td>-0.1770</td>\n",
       "      <td>-0.2573</td>\n",
       "      <td>-0.3465</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>-0.7966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:50:00</th>\n",
       "      <td>0.5865</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0287</td>\n",
       "      <td>-0.0942</td>\n",
       "      <td>-0.1770</td>\n",
       "      <td>-0.2573</td>\n",
       "      <td>-0.3465</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     W_LEV_AVG  dayofweek  month  day  hour  moon_phase  \\\n",
       "DATE                                                                      \n",
       "2023-12-29 03:00:00    -0.6634          4     12   29     3          95   \n",
       "2023-12-29 03:10:00    -0.7622          4     12   29     3          95   \n",
       "2023-12-29 03:20:00    -0.8795          4     12   29     3          95   \n",
       "2023-12-29 03:30:00    -0.9905          4     12   29     3          95   \n",
       "2023-12-29 03:40:00    -1.0927          4     12   29     3          95   \n",
       "...                        ...        ...    ...  ...   ...         ...   \n",
       "2023-12-31 23:10:00     0.3508          6     12   31    23          78   \n",
       "2023-12-31 23:20:00     0.4242          6     12   31    23          78   \n",
       "2023-12-31 23:30:00     0.4790          6     12   31    23          78   \n",
       "2023-12-31 23:40:00     0.5506          6     12   31    23          78   \n",
       "2023-12-31 23:50:00     0.5865          6     12   31    23          78   \n",
       "\n",
       "                     full_moon_days  dark_moon_days  W_LEV_AVG_lag_1  \\\n",
       "DATE                                                                   \n",
       "2023-12-29 03:00:00               0               0          -0.5485   \n",
       "2023-12-29 03:10:00               0               0          -0.6634   \n",
       "2023-12-29 03:20:00               0               0          -0.7622   \n",
       "2023-12-29 03:30:00               0               0          -0.8795   \n",
       "2023-12-29 03:40:00               0               0          -0.9905   \n",
       "...                             ...             ...              ...   \n",
       "2023-12-31 23:10:00               0               0           0.2852   \n",
       "2023-12-31 23:20:00               0               0           0.3508   \n",
       "2023-12-31 23:30:00               0               0           0.4242   \n",
       "2023-12-31 23:40:00               0               0           0.4790   \n",
       "2023-12-31 23:50:00               0               0           0.5506   \n",
       "\n",
       "                     W_LEV_AVG_lag_2  ...  W_LEV_AVG_lag_9  W_LEV_AVG_lag_10  \\\n",
       "DATE                                  ...                                      \n",
       "2023-12-29 03:00:00          -0.4397  ...           0.2917            0.3696   \n",
       "2023-12-29 03:10:00          -0.5485  ...           0.1973            0.2917   \n",
       "2023-12-29 03:20:00          -0.6634  ...           0.0978            0.1973   \n",
       "2023-12-29 03:30:00          -0.7622  ...          -0.0022            0.0978   \n",
       "2023-12-29 03:40:00          -0.8795  ...          -0.1052           -0.0022   \n",
       "...                              ...  ...              ...               ...   \n",
       "2023-12-31 23:10:00           0.2054  ...          -0.3465           -0.4355   \n",
       "2023-12-31 23:20:00           0.2852  ...          -0.2573           -0.3465   \n",
       "2023-12-31 23:30:00           0.3508  ...          -0.1770           -0.2573   \n",
       "2023-12-31 23:40:00           0.4242  ...          -0.0942           -0.1770   \n",
       "2023-12-31 23:50:00           0.4790  ...          -0.0287           -0.0942   \n",
       "\n",
       "                     W_LEV_AVG_lag_11  W_LEV_AVG_lag_12  W_LEV_AVG_lag_13  \\\n",
       "DATE                                                                        \n",
       "2023-12-29 03:00:00            0.4609            0.5445            0.6053   \n",
       "2023-12-29 03:10:00            0.3696            0.4609            0.5445   \n",
       "2023-12-29 03:20:00            0.2917            0.3696            0.4609   \n",
       "2023-12-29 03:30:00            0.1973            0.2917            0.3696   \n",
       "2023-12-29 03:40:00            0.0978            0.1973            0.2917   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-31 23:10:00           -0.5201           -0.6000           -0.6651   \n",
       "2023-12-31 23:20:00           -0.4355           -0.5201           -0.6000   \n",
       "2023-12-31 23:30:00           -0.3465           -0.4355           -0.5201   \n",
       "2023-12-31 23:40:00           -0.2573           -0.3465           -0.4355   \n",
       "2023-12-31 23:50:00           -0.1770           -0.2573           -0.3465   \n",
       "\n",
       "                     W_LEV_AVG_lag_14  W_LEV_AVG_lag_15  W_LEV_AVG_lag_16  \\\n",
       "DATE                                                                        \n",
       "2023-12-29 03:00:00            0.6723            0.7259            0.7828   \n",
       "2023-12-29 03:10:00            0.6053            0.6723            0.7259   \n",
       "2023-12-29 03:20:00            0.5445            0.6053            0.6723   \n",
       "2023-12-29 03:30:00            0.4609            0.5445            0.6053   \n",
       "2023-12-29 03:40:00            0.3696            0.4609            0.5445   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-31 23:10:00           -0.7272           -0.7966           -0.8627   \n",
       "2023-12-31 23:20:00           -0.6651           -0.7272           -0.7966   \n",
       "2023-12-31 23:30:00           -0.6000           -0.6651           -0.7272   \n",
       "2023-12-31 23:40:00           -0.5201           -0.6000           -0.6651   \n",
       "2023-12-31 23:50:00           -0.4355           -0.5201           -0.6000   \n",
       "\n",
       "                     W_LEV_AVG_lag_17  W_LEV_AVG_lag_18  \n",
       "DATE                                                     \n",
       "2023-12-29 03:00:00            0.8169            0.8538  \n",
       "2023-12-29 03:10:00            0.7828            0.8169  \n",
       "2023-12-29 03:20:00            0.7259            0.7828  \n",
       "2023-12-29 03:30:00            0.6723            0.7259  \n",
       "2023-12-29 03:40:00            0.6053            0.6723  \n",
       "...                               ...               ...  \n",
       "2023-12-31 23:10:00           -0.9220           -0.9874  \n",
       "2023-12-31 23:20:00           -0.8627           -0.9220  \n",
       "2023-12-31 23:30:00           -0.7966           -0.8627  \n",
       "2023-12-31 23:40:00           -0.7272           -0.7966  \n",
       "2023-12-31 23:50:00           -0.6651           -0.7272  \n",
       "\n",
       "[414 rows x 26 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_data = df[-432:]\n",
    "df = df[:-432]\n",
    "# Create lag features for the past 14 days\n",
    "for lag in range(1, 19):  # Lags from 1 to 18 (3 hour)\n",
    "    compare_data[f'W_LEV_AVG_lag_{lag}'] = compare_data['W_LEV_AVG'].shift(lag)\n",
    "\n",
    "compare_data.dropna(inplace=True)\n",
    "compare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>moon_phase</th>\n",
       "      <th>full_moon_days</th>\n",
       "      <th>dark_moon_days</th>\n",
       "      <th>W_LEV_AVG_lag_1</th>\n",
       "      <th>W_LEV_AVG_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>W_LEV_AVG_lag_9</th>\n",
       "      <th>W_LEV_AVG_lag_10</th>\n",
       "      <th>W_LEV_AVG_lag_11</th>\n",
       "      <th>W_LEV_AVG_lag_12</th>\n",
       "      <th>W_LEV_AVG_lag_13</th>\n",
       "      <th>W_LEV_AVG_lag_14</th>\n",
       "      <th>W_LEV_AVG_lag_15</th>\n",
       "      <th>W_LEV_AVG_lag_16</th>\n",
       "      <th>W_LEV_AVG_lag_17</th>\n",
       "      <th>W_LEV_AVG_lag_18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:00:00</th>\n",
       "      <td>0.3375</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.4129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:10:00</th>\n",
       "      <td>0.2846</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.4528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:20:00</th>\n",
       "      <td>0.2276</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.4901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:30:00</th>\n",
       "      <td>0.1704</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:40:00</th>\n",
       "      <td>0.1157</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:10:00</th>\n",
       "      <td>0.8914</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.8404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.1637</td>\n",
       "      <td>-0.2607</td>\n",
       "      <td>-0.3692</td>\n",
       "      <td>-0.4605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:20:00</th>\n",
       "      <td>0.9097</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.1637</td>\n",
       "      <td>-0.2607</td>\n",
       "      <td>-0.3692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:30:00</th>\n",
       "      <td>0.9084</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.1637</td>\n",
       "      <td>-0.2607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:40:00</th>\n",
       "      <td>0.9093</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:50:00</th>\n",
       "      <td>0.8893</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404428 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     W_LEV_AVG  dayofweek  month  day  hour  moon_phase  \\\n",
       "DATE                                                                      \n",
       "2013-10-01 10:00:00     0.3375          1     10    1    10          14   \n",
       "2013-10-01 10:10:00     0.2846          1     10    1    10          14   \n",
       "2013-10-01 10:20:00     0.2276          1     10    1    10          14   \n",
       "2013-10-01 10:30:00     0.1704          1     10    1    10          13   \n",
       "2013-10-01 10:40:00     0.1157          1     10    1    10          13   \n",
       "...                        ...        ...    ...  ...   ...         ...   \n",
       "2023-12-28 23:10:00     0.8914          3     12   28    23          96   \n",
       "2023-12-28 23:20:00     0.9097          3     12   28    23          96   \n",
       "2023-12-28 23:30:00     0.9084          3     12   28    23          96   \n",
       "2023-12-28 23:40:00     0.9093          3     12   28    23          96   \n",
       "2023-12-28 23:50:00     0.8893          3     12   28    23          96   \n",
       "\n",
       "                     full_moon_days  dark_moon_days  W_LEV_AVG_lag_1  \\\n",
       "DATE                                                                   \n",
       "2013-10-01 10:00:00               0               0           0.3896   \n",
       "2013-10-01 10:10:00               0               0           0.3375   \n",
       "2013-10-01 10:20:00               0               0           0.2846   \n",
       "2013-10-01 10:30:00               0               0           0.2276   \n",
       "2013-10-01 10:40:00               0               0           0.1704   \n",
       "...                             ...             ...              ...   \n",
       "2023-12-28 23:10:00               0               0           0.8763   \n",
       "2023-12-28 23:20:00               0               0           0.8914   \n",
       "2023-12-28 23:30:00               0               0           0.9097   \n",
       "2023-12-28 23:40:00               0               0           0.9084   \n",
       "2023-12-28 23:50:00               0               0           0.9093   \n",
       "\n",
       "                     W_LEV_AVG_lag_2  ...  W_LEV_AVG_lag_9  W_LEV_AVG_lag_10  \\\n",
       "DATE                                  ...                                      \n",
       "2013-10-01 10:00:00           0.4324  ...           0.5796            0.5914   \n",
       "2013-10-01 10:10:00           0.3896  ...           0.5802            0.5796   \n",
       "2013-10-01 10:20:00           0.3375  ...           0.5575            0.5802   \n",
       "2013-10-01 10:30:00           0.2846  ...           0.5500            0.5575   \n",
       "2013-10-01 10:40:00           0.2276  ...           0.5222            0.5500   \n",
       "...                              ...  ...              ...               ...   \n",
       "2023-12-28 23:10:00           0.8404  ...           0.3855            0.3083   \n",
       "2023-12-28 23:20:00           0.8763  ...           0.4866            0.3855   \n",
       "2023-12-28 23:30:00           0.8914  ...           0.5650            0.4866   \n",
       "2023-12-28 23:40:00           0.9097  ...           0.6441            0.5650   \n",
       "2023-12-28 23:50:00           0.9084  ...           0.7120            0.6441   \n",
       "\n",
       "                     W_LEV_AVG_lag_11  W_LEV_AVG_lag_12  W_LEV_AVG_lag_13  \\\n",
       "DATE                                                                        \n",
       "2013-10-01 10:00:00            0.5791            0.5775            0.5645   \n",
       "2013-10-01 10:10:00            0.5914            0.5791            0.5775   \n",
       "2013-10-01 10:20:00            0.5796            0.5914            0.5791   \n",
       "2013-10-01 10:30:00            0.5802            0.5796            0.5914   \n",
       "2013-10-01 10:40:00            0.5575            0.5802            0.5796   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-28 23:10:00            0.2271            0.1334            0.0397   \n",
       "2023-12-28 23:20:00            0.3083            0.2271            0.1334   \n",
       "2023-12-28 23:30:00            0.3855            0.3083            0.2271   \n",
       "2023-12-28 23:40:00            0.4866            0.3855            0.3083   \n",
       "2023-12-28 23:50:00            0.5650            0.4866            0.3855   \n",
       "\n",
       "                     W_LEV_AVG_lag_14  W_LEV_AVG_lag_15  W_LEV_AVG_lag_16  \\\n",
       "DATE                                                                        \n",
       "2013-10-01 10:00:00            0.5468            0.5079            0.4901   \n",
       "2013-10-01 10:10:00            0.5645            0.5468            0.5079   \n",
       "2013-10-01 10:20:00            0.5775            0.5645            0.5468   \n",
       "2013-10-01 10:30:00            0.5791            0.5775            0.5645   \n",
       "2013-10-01 10:40:00            0.5914            0.5791            0.5775   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-28 23:10:00           -0.0572           -0.1637           -0.2607   \n",
       "2023-12-28 23:20:00            0.0397           -0.0572           -0.1637   \n",
       "2023-12-28 23:30:00            0.1334            0.0397           -0.0572   \n",
       "2023-12-28 23:40:00            0.2271            0.1334            0.0397   \n",
       "2023-12-28 23:50:00            0.3083            0.2271            0.1334   \n",
       "\n",
       "                     W_LEV_AVG_lag_17  W_LEV_AVG_lag_18  \n",
       "DATE                                                     \n",
       "2013-10-01 10:00:00            0.4528            0.4129  \n",
       "2013-10-01 10:10:00            0.4901            0.4528  \n",
       "2013-10-01 10:20:00            0.5079            0.4901  \n",
       "2013-10-01 10:30:00            0.5468            0.5079  \n",
       "2013-10-01 10:40:00            0.5645            0.5468  \n",
       "...                               ...               ...  \n",
       "2023-12-28 23:10:00           -0.3692           -0.4605  \n",
       "2023-12-28 23:20:00           -0.2607           -0.3692  \n",
       "2023-12-28 23:30:00           -0.1637           -0.2607  \n",
       "2023-12-28 23:40:00           -0.0572           -0.1637  \n",
       "2023-12-28 23:50:00            0.0397           -0.0572  \n",
       "\n",
       "[404428 rows x 26 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lag features for the past 14 days\n",
    "for lag in range(1, 19):  # Lags from 1 to 18 (3 hour)\n",
    "    df[f'W_LEV_AVG_lag_{lag}'] = df['W_LEV_AVG'].shift(lag)\n",
    "\n",
    "# Drop NaN values caused by shifting\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b4d42_row8_col1, #T_b4d42_row12_col1, #T_b4d42_row17_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b4d42\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b4d42_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_b4d42_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b4d42_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_b4d42_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b4d42_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_b4d42_row1_col1\" class=\"data row1 col1\" >W_LEV_AVG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b4d42_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_b4d42_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b4d42_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_b4d42_row3_col1\" class=\"data row3 col1\" >(400540, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b4d42_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_b4d42_row4_col1\" class=\"data row4 col1\" >(384518, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b4d42_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_b4d42_row5_col1\" class=\"data row5 col1\" >(304410, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b4d42_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_b4d42_row6_col1\" class=\"data row6 col1\" >(80108, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b4d42_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_b4d42_row7_col1\" class=\"data row7 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b4d42_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_b4d42_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b4d42_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_b4d42_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b4d42_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_b4d42_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b4d42_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_b4d42_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b4d42_row12_col0\" class=\"data row12 col0\" >Remove outliers</td>\n",
       "      <td id=\"T_b4d42_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b4d42_row13_col0\" class=\"data row13 col0\" >Outliers threshold</td>\n",
       "      <td id=\"T_b4d42_row13_col1\" class=\"data row13 col1\" >0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b4d42_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_b4d42_row14_col1\" class=\"data row14 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b4d42_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
       "      <td id=\"T_b4d42_row15_col1\" class=\"data row15 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b4d42_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_b4d42_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b4d42_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
       "      <td id=\"T_b4d42_row17_col1\" class=\"data row17 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b4d42_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_b4d42_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_b4d42_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_b4d42_row19_col1\" class=\"data row19 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4d42_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_b4d42_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
       "      <td id=\"T_b4d42_row20_col1\" class=\"data row20 col1\" >cc1a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a85214c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "exp = setup(data=df, target='W_LEV_AVG', fold=10, train_size=0.8, session_id=123, iterative_imputation_iters=100, remove_outliers = True, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9b257 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9b257_row0_col0, #T_9b257_row0_col1, #T_9b257_row0_col2, #T_9b257_row0_col3, #T_9b257_row0_col5, #T_9b257_row0_col6, #T_9b257_row1_col0, #T_9b257_row1_col1, #T_9b257_row1_col2, #T_9b257_row1_col3, #T_9b257_row1_col5, #T_9b257_row1_col6, #T_9b257_row2_col0, #T_9b257_row2_col1, #T_9b257_row2_col2, #T_9b257_row2_col3, #T_9b257_row2_col5, #T_9b257_row2_col6, #T_9b257_row3_col0, #T_9b257_row4_col0, #T_9b257_row4_col1, #T_9b257_row4_col2, #T_9b257_row4_col3, #T_9b257_row4_col4, #T_9b257_row4_col5, #T_9b257_row4_col6, #T_9b257_row5_col0, #T_9b257_row5_col1, #T_9b257_row5_col2, #T_9b257_row5_col3, #T_9b257_row5_col4, #T_9b257_row5_col5, #T_9b257_row5_col6, #T_9b257_row6_col0, #T_9b257_row6_col1, #T_9b257_row6_col2, #T_9b257_row6_col3, #T_9b257_row6_col4, #T_9b257_row6_col5, #T_9b257_row6_col6, #T_9b257_row7_col0, #T_9b257_row7_col1, #T_9b257_row7_col2, #T_9b257_row7_col3, #T_9b257_row7_col4, #T_9b257_row7_col5, #T_9b257_row7_col6, #T_9b257_row8_col0, #T_9b257_row8_col1, #T_9b257_row8_col2, #T_9b257_row8_col3, #T_9b257_row8_col4, #T_9b257_row8_col5, #T_9b257_row8_col6, #T_9b257_row9_col0, #T_9b257_row9_col1, #T_9b257_row9_col2, #T_9b257_row9_col3, #T_9b257_row9_col4, #T_9b257_row9_col5, #T_9b257_row9_col6, #T_9b257_row10_col0, #T_9b257_row10_col1, #T_9b257_row10_col2, #T_9b257_row10_col3, #T_9b257_row10_col4, #T_9b257_row10_col5, #T_9b257_row10_col6, #T_9b257_row11_col0, #T_9b257_row11_col1, #T_9b257_row11_col2, #T_9b257_row11_col3, #T_9b257_row11_col4, #T_9b257_row11_col5, #T_9b257_row11_col6, #T_9b257_row12_col0, #T_9b257_row12_col1, #T_9b257_row12_col2, #T_9b257_row12_col3, #T_9b257_row12_col4, #T_9b257_row12_col5, #T_9b257_row12_col6, #T_9b257_row13_col0, #T_9b257_row13_col1, #T_9b257_row13_col2, #T_9b257_row13_col3, #T_9b257_row13_col4, #T_9b257_row13_col5, #T_9b257_row13_col6, #T_9b257_row14_col0, #T_9b257_row14_col1, #T_9b257_row14_col2, #T_9b257_row14_col3, #T_9b257_row14_col4, #T_9b257_row14_col5, #T_9b257_row14_col6, #T_9b257_row15_col0, #T_9b257_row15_col1, #T_9b257_row15_col2, #T_9b257_row15_col3, #T_9b257_row15_col4, #T_9b257_row15_col5, #T_9b257_row15_col6, #T_9b257_row16_col0, #T_9b257_row16_col1, #T_9b257_row16_col2, #T_9b257_row16_col3, #T_9b257_row16_col4, #T_9b257_row16_col5, #T_9b257_row16_col6, #T_9b257_row17_col0, #T_9b257_row17_col1, #T_9b257_row17_col2, #T_9b257_row17_col3, #T_9b257_row17_col4, #T_9b257_row17_col5, #T_9b257_row17_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9b257_row0_col4, #T_9b257_row1_col4, #T_9b257_row2_col4, #T_9b257_row3_col1, #T_9b257_row3_col2, #T_9b257_row3_col3, #T_9b257_row3_col4, #T_9b257_row3_col5, #T_9b257_row3_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_9b257_row0_col7, #T_9b257_row1_col7, #T_9b257_row2_col7, #T_9b257_row3_col7, #T_9b257_row4_col7, #T_9b257_row5_col7, #T_9b257_row6_col7, #T_9b257_row7_col7, #T_9b257_row8_col7, #T_9b257_row9_col7, #T_9b257_row10_col7, #T_9b257_row11_col7, #T_9b257_row12_col7, #T_9b257_row13_col7, #T_9b257_row15_col7, #T_9b257_row16_col7, #T_9b257_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_9b257_row14_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9b257\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9b257_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_9b257_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_9b257_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_9b257_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_9b257_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_9b257_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_9b257_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_9b257_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_9b257_row0_col0\" class=\"data row0 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_9b257_row0_col1\" class=\"data row0 col1\" >0.0127</td>\n",
       "      <td id=\"T_9b257_row0_col2\" class=\"data row0 col2\" >0.0008</td>\n",
       "      <td id=\"T_9b257_row0_col3\" class=\"data row0 col3\" >0.0272</td>\n",
       "      <td id=\"T_9b257_row0_col4\" class=\"data row0 col4\" >0.9988</td>\n",
       "      <td id=\"T_9b257_row0_col5\" class=\"data row0 col5\" >0.0159</td>\n",
       "      <td id=\"T_9b257_row0_col6\" class=\"data row0 col6\" >0.0912</td>\n",
       "      <td id=\"T_9b257_row0_col7\" class=\"data row0 col7\" >3.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row1\" class=\"row_heading level0 row1\" >ridge</th>\n",
       "      <td id=\"T_9b257_row1_col0\" class=\"data row1 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_9b257_row1_col1\" class=\"data row1 col1\" >0.0127</td>\n",
       "      <td id=\"T_9b257_row1_col2\" class=\"data row1 col2\" >0.0008</td>\n",
       "      <td id=\"T_9b257_row1_col3\" class=\"data row1 col3\" >0.0273</td>\n",
       "      <td id=\"T_9b257_row1_col4\" class=\"data row1 col4\" >0.9988</td>\n",
       "      <td id=\"T_9b257_row1_col5\" class=\"data row1 col5\" >0.0159</td>\n",
       "      <td id=\"T_9b257_row1_col6\" class=\"data row1 col6\" >0.0912</td>\n",
       "      <td id=\"T_9b257_row1_col7\" class=\"data row1 col7\" >3.2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row2\" class=\"row_heading level0 row2\" >br</th>\n",
       "      <td id=\"T_9b257_row2_col0\" class=\"data row2 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_9b257_row2_col1\" class=\"data row2 col1\" >0.0127</td>\n",
       "      <td id=\"T_9b257_row2_col2\" class=\"data row2 col2\" >0.0008</td>\n",
       "      <td id=\"T_9b257_row2_col3\" class=\"data row2 col3\" >0.0272</td>\n",
       "      <td id=\"T_9b257_row2_col4\" class=\"data row2 col4\" >0.9988</td>\n",
       "      <td id=\"T_9b257_row2_col5\" class=\"data row2 col5\" >0.0159</td>\n",
       "      <td id=\"T_9b257_row2_col6\" class=\"data row2 col6\" >0.0912</td>\n",
       "      <td id=\"T_9b257_row2_col7\" class=\"data row2 col7\" >4.1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n",
       "      <td id=\"T_9b257_row3_col0\" class=\"data row3 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_9b257_row3_col1\" class=\"data row3 col1\" >0.0119</td>\n",
       "      <td id=\"T_9b257_row3_col2\" class=\"data row3 col2\" >0.0007</td>\n",
       "      <td id=\"T_9b257_row3_col3\" class=\"data row3 col3\" >0.0266</td>\n",
       "      <td id=\"T_9b257_row3_col4\" class=\"data row3 col4\" >0.9988</td>\n",
       "      <td id=\"T_9b257_row3_col5\" class=\"data row3 col5\" >0.0154</td>\n",
       "      <td id=\"T_9b257_row3_col6\" class=\"data row3 col6\" >0.0820</td>\n",
       "      <td id=\"T_9b257_row3_col7\" class=\"data row3 col7\" >45.8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row4\" class=\"row_heading level0 row4\" >rf</th>\n",
       "      <td id=\"T_9b257_row4_col0\" class=\"data row4 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_9b257_row4_col1\" class=\"data row4 col1\" >0.0126</td>\n",
       "      <td id=\"T_9b257_row4_col2\" class=\"data row4 col2\" >0.0009</td>\n",
       "      <td id=\"T_9b257_row4_col3\" class=\"data row4 col3\" >0.0305</td>\n",
       "      <td id=\"T_9b257_row4_col4\" class=\"data row4 col4\" >0.9985</td>\n",
       "      <td id=\"T_9b257_row4_col5\" class=\"data row4 col5\" >0.0170</td>\n",
       "      <td id=\"T_9b257_row4_col6\" class=\"data row4 col6\" >0.0840</td>\n",
       "      <td id=\"T_9b257_row4_col7\" class=\"data row4 col7\" >115.6830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row5\" class=\"row_heading level0 row5\" >lightgbm</th>\n",
       "      <td id=\"T_9b257_row5_col0\" class=\"data row5 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_9b257_row5_col1\" class=\"data row5 col1\" >0.0153</td>\n",
       "      <td id=\"T_9b257_row5_col2\" class=\"data row5 col2\" >0.0010</td>\n",
       "      <td id=\"T_9b257_row5_col3\" class=\"data row5 col3\" >0.0309</td>\n",
       "      <td id=\"T_9b257_row5_col4\" class=\"data row5 col4\" >0.9984</td>\n",
       "      <td id=\"T_9b257_row5_col5\" class=\"data row5 col5\" >0.0176</td>\n",
       "      <td id=\"T_9b257_row5_col6\" class=\"data row5 col6\" >0.1031</td>\n",
       "      <td id=\"T_9b257_row5_col7\" class=\"data row5 col7\" >5.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row6\" class=\"row_heading level0 row6\" >gbr</th>\n",
       "      <td id=\"T_9b257_row6_col0\" class=\"data row6 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_9b257_row6_col1\" class=\"data row6 col1\" >0.0193</td>\n",
       "      <td id=\"T_9b257_row6_col2\" class=\"data row6 col2\" >0.0013</td>\n",
       "      <td id=\"T_9b257_row6_col3\" class=\"data row6 col3\" >0.0360</td>\n",
       "      <td id=\"T_9b257_row6_col4\" class=\"data row6 col4\" >0.9978</td>\n",
       "      <td id=\"T_9b257_row6_col5\" class=\"data row6 col5\" >0.0219</td>\n",
       "      <td id=\"T_9b257_row6_col6\" class=\"data row6 col6\" >0.1351</td>\n",
       "      <td id=\"T_9b257_row6_col7\" class=\"data row6 col7\" >183.8270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row7\" class=\"row_heading level0 row7\" >dt</th>\n",
       "      <td id=\"T_9b257_row7_col0\" class=\"data row7 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_9b257_row7_col1\" class=\"data row7 col1\" >0.0176</td>\n",
       "      <td id=\"T_9b257_row7_col2\" class=\"data row7 col2\" >0.0017</td>\n",
       "      <td id=\"T_9b257_row7_col3\" class=\"data row7 col3\" >0.0409</td>\n",
       "      <td id=\"T_9b257_row7_col4\" class=\"data row7 col4\" >0.9972</td>\n",
       "      <td id=\"T_9b257_row7_col5\" class=\"data row7 col5\" >0.0227</td>\n",
       "      <td id=\"T_9b257_row7_col6\" class=\"data row7 col6\" >0.1177</td>\n",
       "      <td id=\"T_9b257_row7_col7\" class=\"data row7 col7\" >15.6540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row8\" class=\"row_heading level0 row8\" >par</th>\n",
       "      <td id=\"T_9b257_row8_col0\" class=\"data row8 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_9b257_row8_col1\" class=\"data row8 col1\" >0.0378</td>\n",
       "      <td id=\"T_9b257_row8_col2\" class=\"data row8 col2\" >0.0027</td>\n",
       "      <td id=\"T_9b257_row8_col3\" class=\"data row8 col3\" >0.0516</td>\n",
       "      <td id=\"T_9b257_row8_col4\" class=\"data row8 col4\" >0.9955</td>\n",
       "      <td id=\"T_9b257_row8_col5\" class=\"data row8 col5\" >0.0318</td>\n",
       "      <td id=\"T_9b257_row8_col6\" class=\"data row8 col6\" >0.2642</td>\n",
       "      <td id=\"T_9b257_row8_col7\" class=\"data row8 col7\" >3.9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row9\" class=\"row_heading level0 row9\" >huber</th>\n",
       "      <td id=\"T_9b257_row9_col0\" class=\"data row9 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_9b257_row9_col1\" class=\"data row9 col1\" >0.0387</td>\n",
       "      <td id=\"T_9b257_row9_col2\" class=\"data row9 col2\" >0.0048</td>\n",
       "      <td id=\"T_9b257_row9_col3\" class=\"data row9 col3\" >0.0690</td>\n",
       "      <td id=\"T_9b257_row9_col4\" class=\"data row9 col4\" >0.9921</td>\n",
       "      <td id=\"T_9b257_row9_col5\" class=\"data row9 col5\" >0.0409</td>\n",
       "      <td id=\"T_9b257_row9_col6\" class=\"data row9 col6\" >0.2683</td>\n",
       "      <td id=\"T_9b257_row9_col7\" class=\"data row9 col7\" >12.3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row10\" class=\"row_heading level0 row10\" >omp</th>\n",
       "      <td id=\"T_9b257_row10_col0\" class=\"data row10 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_9b257_row10_col1\" class=\"data row10 col1\" >0.0709</td>\n",
       "      <td id=\"T_9b257_row10_col2\" class=\"data row10 col2\" >0.0130</td>\n",
       "      <td id=\"T_9b257_row10_col3\" class=\"data row10 col3\" >0.1142</td>\n",
       "      <td id=\"T_9b257_row10_col4\" class=\"data row10 col4\" >0.9784</td>\n",
       "      <td id=\"T_9b257_row10_col5\" class=\"data row10 col5\" >0.0691</td>\n",
       "      <td id=\"T_9b257_row10_col6\" class=\"data row10 col6\" >0.5810</td>\n",
       "      <td id=\"T_9b257_row10_col7\" class=\"data row10 col7\" >3.8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row11\" class=\"row_heading level0 row11\" >knn</th>\n",
       "      <td id=\"T_9b257_row11_col0\" class=\"data row11 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_9b257_row11_col1\" class=\"data row11 col1\" >0.0841</td>\n",
       "      <td id=\"T_9b257_row11_col2\" class=\"data row11 col2\" >0.0233</td>\n",
       "      <td id=\"T_9b257_row11_col3\" class=\"data row11 col3\" >0.1525</td>\n",
       "      <td id=\"T_9b257_row11_col4\" class=\"data row11 col4\" >0.9614</td>\n",
       "      <td id=\"T_9b257_row11_col5\" class=\"data row11 col5\" >0.0857</td>\n",
       "      <td id=\"T_9b257_row11_col6\" class=\"data row11 col6\" >0.6264</td>\n",
       "      <td id=\"T_9b257_row11_col7\" class=\"data row11 col7\" >10.7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row12\" class=\"row_heading level0 row12\" >ada</th>\n",
       "      <td id=\"T_9b257_row12_col0\" class=\"data row12 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_9b257_row12_col1\" class=\"data row12 col1\" >0.1475</td>\n",
       "      <td id=\"T_9b257_row12_col2\" class=\"data row12 col2\" >0.0347</td>\n",
       "      <td id=\"T_9b257_row12_col3\" class=\"data row12 col3\" >0.1857</td>\n",
       "      <td id=\"T_9b257_row12_col4\" class=\"data row12 col4\" >0.9425</td>\n",
       "      <td id=\"T_9b257_row12_col5\" class=\"data row12 col5\" >0.1155</td>\n",
       "      <td id=\"T_9b257_row12_col6\" class=\"data row12 col6\" >0.5659</td>\n",
       "      <td id=\"T_9b257_row12_col7\" class=\"data row12 col7\" >73.6680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row13\" class=\"row_heading level0 row13\" >en</th>\n",
       "      <td id=\"T_9b257_row13_col0\" class=\"data row13 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_9b257_row13_col1\" class=\"data row13 col1\" >0.6155</td>\n",
       "      <td id=\"T_9b257_row13_col2\" class=\"data row13 col2\" >0.5331</td>\n",
       "      <td id=\"T_9b257_row13_col3\" class=\"data row13 col3\" >0.7301</td>\n",
       "      <td id=\"T_9b257_row13_col4\" class=\"data row13 col4\" >0.1162</td>\n",
       "      <td id=\"T_9b257_row13_col5\" class=\"data row13 col5\" >0.3819</td>\n",
       "      <td id=\"T_9b257_row13_col6\" class=\"data row13 col6\" >2.1002</td>\n",
       "      <td id=\"T_9b257_row13_col7\" class=\"data row13 col7\" >3.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row14\" class=\"row_heading level0 row14\" >lasso</th>\n",
       "      <td id=\"T_9b257_row14_col0\" class=\"data row14 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_9b257_row14_col1\" class=\"data row14 col1\" >0.6547</td>\n",
       "      <td id=\"T_9b257_row14_col2\" class=\"data row14 col2\" >0.6032</td>\n",
       "      <td id=\"T_9b257_row14_col3\" class=\"data row14 col3\" >0.7766</td>\n",
       "      <td id=\"T_9b257_row14_col4\" class=\"data row14 col4\" >-0.0000</td>\n",
       "      <td id=\"T_9b257_row14_col5\" class=\"data row14 col5\" >0.3886</td>\n",
       "      <td id=\"T_9b257_row14_col6\" class=\"data row14 col6\" >2.2371</td>\n",
       "      <td id=\"T_9b257_row14_col7\" class=\"data row14 col7\" >2.9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row15\" class=\"row_heading level0 row15\" >llar</th>\n",
       "      <td id=\"T_9b257_row15_col0\" class=\"data row15 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_9b257_row15_col1\" class=\"data row15 col1\" >0.6547</td>\n",
       "      <td id=\"T_9b257_row15_col2\" class=\"data row15 col2\" >0.6032</td>\n",
       "      <td id=\"T_9b257_row15_col3\" class=\"data row15 col3\" >0.7766</td>\n",
       "      <td id=\"T_9b257_row15_col4\" class=\"data row15 col4\" >-0.0000</td>\n",
       "      <td id=\"T_9b257_row15_col5\" class=\"data row15 col5\" >0.3886</td>\n",
       "      <td id=\"T_9b257_row15_col6\" class=\"data row15 col6\" >2.2371</td>\n",
       "      <td id=\"T_9b257_row15_col7\" class=\"data row15 col7\" >4.0830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row16\" class=\"row_heading level0 row16\" >dummy</th>\n",
       "      <td id=\"T_9b257_row16_col0\" class=\"data row16 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_9b257_row16_col1\" class=\"data row16 col1\" >0.6547</td>\n",
       "      <td id=\"T_9b257_row16_col2\" class=\"data row16 col2\" >0.6032</td>\n",
       "      <td id=\"T_9b257_row16_col3\" class=\"data row16 col3\" >0.7766</td>\n",
       "      <td id=\"T_9b257_row16_col4\" class=\"data row16 col4\" >-0.0000</td>\n",
       "      <td id=\"T_9b257_row16_col5\" class=\"data row16 col5\" >0.3886</td>\n",
       "      <td id=\"T_9b257_row16_col6\" class=\"data row16 col6\" >2.2371</td>\n",
       "      <td id=\"T_9b257_row16_col7\" class=\"data row16 col7\" >3.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b257_level0_row17\" class=\"row_heading level0 row17\" >lar</th>\n",
       "      <td id=\"T_9b257_row17_col0\" class=\"data row17 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_9b257_row17_col1\" class=\"data row17 col1\" >1.4368</td>\n",
       "      <td id=\"T_9b257_row17_col2\" class=\"data row17 col2\" >26.7128</td>\n",
       "      <td id=\"T_9b257_row17_col3\" class=\"data row17 col3\" >3.1119</td>\n",
       "      <td id=\"T_9b257_row17_col4\" class=\"data row17 col4\" >-43.5329</td>\n",
       "      <td id=\"T_9b257_row17_col5\" class=\"data row17 col5\" >0.5304</td>\n",
       "      <td id=\"T_9b257_row17_col6\" class=\"data row17 col6\" >10.3755</td>\n",
       "      <td id=\"T_9b257_row17_col7\" class=\"data row17 col7\" >4.0470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a9cbe4810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = exp.compare_models()  # Find the best regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>19:43:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Extra Trees Regressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     \n",
       "                                                                     \n",
       "Initiated  . . . . . . . . . . . . . . . . . .               19:43:05\n",
       "Status     . . . . . . . . . . . . . . . . . .       Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Extra Trees Regressor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8afad59882c4c999a223a1e3e09b27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[252], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43met\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\regression\\functional.py:990\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(estimator, fold, round, cross_validation, fit_kwargs, groups, experiment_custom_tags, engine, verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_model\u001b[39m(\n\u001b[0;32m    864\u001b[0m     estimator: Union[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    875\u001b[0m ):\n\u001b[0;32m    876\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;124;03m    This function trains and evaluates the performance of a given estimator\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m    using cross validation. The output of this function is a score grid with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m \n\u001b[0;32m    988\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CURRENT_EXPERIMENT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\regression\\oop.py:1285\u001b[0m, in \u001b[0;36mRegressionExperiment.create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, fit_kwargs, groups, experiment_custom_tags, engine, verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_engine(estimator\u001b[38;5;241m=\u001b[39mestimator, engine\u001b[38;5;241m=\u001b[39mengine, severity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1285\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1299\u001b[0m         \u001b[38;5;66;03m# Reset the models back to the default engines\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1766\u001b[0m, in \u001b[0;36m_SupervisedExperiment.create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;66;03m# TODO improve error message\u001b[39;00m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1756\u001b[0m     x\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m   1765\u001b[0m )\n\u001b[1;32m-> 1766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1533\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, system, add_to_model_list, X_train_data, y_train_data, metrics, display, model_only, return_train_score, error_score, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model, model_fit_time\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m-> 1533\u001b[0m model, model_fit_time, model_results, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model_with_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;66;03m# end runtime\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m runtime_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1126\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model_with_cv\u001b[1;34m(self, model, data_X, data_y, fit_kwargs, round, cv, groups, metrics, refit, system, display, error_score, return_train_score)\u001b[0m\n\u001b[0;32m   1124\u001b[0m     model_fit_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m redirect_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger):\n\u001b[1;32m-> 1126\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpipeline_with_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m model_fit_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1140\u001b[0m model_fit_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model_fit_end \u001b[38;5;241m-\u001b[39m model_fit_start)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\internal\\patches\\sklearn.py:140\u001b[0m, in \u001b[0;36mfit_and_score\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._validation._MultimetricScorer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    136\u001b[0m         MultimetricScorerPatched,\n\u001b[0;32m    137\u001b[0m     ), patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._validation._score\u001b[39m\u001b[38;5;124m\"\u001b[39m, score(_score)):\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _fit_and_score(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\internal\\patches\\sklearn.py:138\u001b[0m, in \u001b[0;36mfit_and_score.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._validation._MultimetricScorer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    136\u001b[0m         MultimetricScorerPatched,\n\u001b[0;32m    137\u001b[0m     ), patch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._validation._score\u001b[39m\u001b[38;5;124m\"\u001b[39m, score(_score)):\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fit_and_score\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\internal\\pipeline.py:278\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    277\u001b[0m     last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 278\u001b[0m     fitted_estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_memory_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# Hacky way to make sure that the state of the estimator\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# loaded from cache is carried over to the estimator\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# in steps\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     _copy_estimator_state(fitted_estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\pycaret\\internal\\pipeline.py:69\u001b[0m, in \u001b[0;36m_fit_one\u001b[1;34m(transformer, X, y, message, params)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m signature(transformer\u001b[38;5;241m.\u001b[39mfit)\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[0;32m     68\u001b[0m             args\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[1;32m---> 69\u001b[0m         \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformer\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\OneDrive\\Desktop\\pm2_5_term_project\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = create_model('et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_78902\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_78902_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_78902_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_78902_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_78902_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_78902_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_78902_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_78902_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_78902_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_78902_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_78902_row0_col1\" class=\"data row0 col1\" >0.0132</td>\n",
       "      <td id=\"T_78902_row0_col2\" class=\"data row0 col2\" >0.0003</td>\n",
       "      <td id=\"T_78902_row0_col3\" class=\"data row0 col3\" >0.0162</td>\n",
       "      <td id=\"T_78902_row0_col4\" class=\"data row0 col4\" >0.9995</td>\n",
       "      <td id=\"T_78902_row0_col5\" class=\"data row0 col5\" >0.0101</td>\n",
       "      <td id=\"T_78902_row0_col6\" class=\"data row0 col6\" >0.0609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a985df510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>moon_phase</th>\n",
       "      <th>full_moon_days</th>\n",
       "      <th>dark_moon_days</th>\n",
       "      <th>W_LEV_AVG_lag_1</th>\n",
       "      <th>W_LEV_AVG_lag_2</th>\n",
       "      <th>W_LEV_AVG_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>W_LEV_AVG_lag_11</th>\n",
       "      <th>W_LEV_AVG_lag_12</th>\n",
       "      <th>W_LEV_AVG_lag_13</th>\n",
       "      <th>W_LEV_AVG_lag_14</th>\n",
       "      <th>W_LEV_AVG_lag_15</th>\n",
       "      <th>W_LEV_AVG_lag_16</th>\n",
       "      <th>W_LEV_AVG_lag_17</th>\n",
       "      <th>W_LEV_AVG_lag_18</th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5485</td>\n",
       "      <td>-0.4397</td>\n",
       "      <td>-0.3273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>-0.6634</td>\n",
       "      <td>-0.655454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:10:00</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.6634</td>\n",
       "      <td>-0.5485</td>\n",
       "      <td>-0.4397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>-0.7622</td>\n",
       "      <td>-0.765626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:20:00</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.7622</td>\n",
       "      <td>-0.6634</td>\n",
       "      <td>-0.5485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>-0.8795</td>\n",
       "      <td>-0.861801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:30:00</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8795</td>\n",
       "      <td>-0.7622</td>\n",
       "      <td>-0.6634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>-0.9905</td>\n",
       "      <td>-0.966176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 03:40:00</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9905</td>\n",
       "      <td>-0.8795</td>\n",
       "      <td>-0.7622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3696</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>-1.0927</td>\n",
       "      <td>-1.080737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:10:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>-0.7966</td>\n",
       "      <td>-0.8627</td>\n",
       "      <td>-0.9220</td>\n",
       "      <td>-0.9874</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.360075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:20:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>-0.7966</td>\n",
       "      <td>-0.8627</td>\n",
       "      <td>-0.9220</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.413450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:30:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3465</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>-0.7966</td>\n",
       "      <td>-0.8627</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.486030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:40:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2573</td>\n",
       "      <td>-0.3465</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>-0.7966</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>0.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:50:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1770</td>\n",
       "      <td>-0.2573</td>\n",
       "      <td>-0.3465</td>\n",
       "      <td>-0.4355</td>\n",
       "      <td>-0.5201</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>-0.6651</td>\n",
       "      <td>-0.7272</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>0.617664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dayofweek  month  day  hour  moon_phase  full_moon_days  \\\n",
       "DATE                                                                           \n",
       "2023-12-29 03:00:00          4     12   29     3          95               0   \n",
       "2023-12-29 03:10:00          4     12   29     3          95               0   \n",
       "2023-12-29 03:20:00          4     12   29     3          95               0   \n",
       "2023-12-29 03:30:00          4     12   29     3          95               0   \n",
       "2023-12-29 03:40:00          4     12   29     3          95               0   \n",
       "...                        ...    ...  ...   ...         ...             ...   \n",
       "2023-12-31 23:10:00          6     12   31    23          78               0   \n",
       "2023-12-31 23:20:00          6     12   31    23          78               0   \n",
       "2023-12-31 23:30:00          6     12   31    23          78               0   \n",
       "2023-12-31 23:40:00          6     12   31    23          78               0   \n",
       "2023-12-31 23:50:00          6     12   31    23          78               0   \n",
       "\n",
       "                     dark_moon_days  W_LEV_AVG_lag_1  W_LEV_AVG_lag_2  \\\n",
       "DATE                                                                    \n",
       "2023-12-29 03:00:00               0          -0.5485          -0.4397   \n",
       "2023-12-29 03:10:00               0          -0.6634          -0.5485   \n",
       "2023-12-29 03:20:00               0          -0.7622          -0.6634   \n",
       "2023-12-29 03:30:00               0          -0.8795          -0.7622   \n",
       "2023-12-29 03:40:00               0          -0.9905          -0.8795   \n",
       "...                             ...              ...              ...   \n",
       "2023-12-31 23:10:00               0           0.2852           0.2054   \n",
       "2023-12-31 23:20:00               0           0.3508           0.2852   \n",
       "2023-12-31 23:30:00               0           0.4242           0.3508   \n",
       "2023-12-31 23:40:00               0           0.4790           0.4242   \n",
       "2023-12-31 23:50:00               0           0.5506           0.4790   \n",
       "\n",
       "                     W_LEV_AVG_lag_3  ...  W_LEV_AVG_lag_11  W_LEV_AVG_lag_12  \\\n",
       "DATE                                  ...                                       \n",
       "2023-12-29 03:00:00          -0.3273  ...            0.4609            0.5445   \n",
       "2023-12-29 03:10:00          -0.4397  ...            0.3696            0.4609   \n",
       "2023-12-29 03:20:00          -0.5485  ...            0.2917            0.3696   \n",
       "2023-12-29 03:30:00          -0.6634  ...            0.1973            0.2917   \n",
       "2023-12-29 03:40:00          -0.7622  ...            0.0978            0.1973   \n",
       "...                              ...  ...               ...               ...   \n",
       "2023-12-31 23:10:00           0.1213  ...           -0.5201           -0.6000   \n",
       "2023-12-31 23:20:00           0.2054  ...           -0.4355           -0.5201   \n",
       "2023-12-31 23:30:00           0.2852  ...           -0.3465           -0.4355   \n",
       "2023-12-31 23:40:00           0.3508  ...           -0.2573           -0.3465   \n",
       "2023-12-31 23:50:00           0.4242  ...           -0.1770           -0.2573   \n",
       "\n",
       "                     W_LEV_AVG_lag_13  W_LEV_AVG_lag_14  W_LEV_AVG_lag_15  \\\n",
       "DATE                                                                        \n",
       "2023-12-29 03:00:00            0.6053            0.6723            0.7259   \n",
       "2023-12-29 03:10:00            0.5445            0.6053            0.6723   \n",
       "2023-12-29 03:20:00            0.4609            0.5445            0.6053   \n",
       "2023-12-29 03:30:00            0.3696            0.4609            0.5445   \n",
       "2023-12-29 03:40:00            0.2917            0.3696            0.4609   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-31 23:10:00           -0.6651           -0.7272           -0.7966   \n",
       "2023-12-31 23:20:00           -0.6000           -0.6651           -0.7272   \n",
       "2023-12-31 23:30:00           -0.5201           -0.6000           -0.6651   \n",
       "2023-12-31 23:40:00           -0.4355           -0.5201           -0.6000   \n",
       "2023-12-31 23:50:00           -0.3465           -0.4355           -0.5201   \n",
       "\n",
       "                     W_LEV_AVG_lag_16  W_LEV_AVG_lag_17  W_LEV_AVG_lag_18  \\\n",
       "DATE                                                                        \n",
       "2023-12-29 03:00:00            0.7828            0.8169            0.8538   \n",
       "2023-12-29 03:10:00            0.7259            0.7828            0.8169   \n",
       "2023-12-29 03:20:00            0.6723            0.7259            0.7828   \n",
       "2023-12-29 03:30:00            0.6053            0.6723            0.7259   \n",
       "2023-12-29 03:40:00            0.5445            0.6053            0.6723   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-31 23:10:00           -0.8627           -0.9220           -0.9874   \n",
       "2023-12-31 23:20:00           -0.7966           -0.8627           -0.9220   \n",
       "2023-12-31 23:30:00           -0.7272           -0.7966           -0.8627   \n",
       "2023-12-31 23:40:00           -0.6651           -0.7272           -0.7966   \n",
       "2023-12-31 23:50:00           -0.6000           -0.6651           -0.7272   \n",
       "\n",
       "                     W_LEV_AVG  prediction_label  \n",
       "DATE                                              \n",
       "2023-12-29 03:00:00    -0.6634         -0.655454  \n",
       "2023-12-29 03:10:00    -0.7622         -0.765626  \n",
       "2023-12-29 03:20:00    -0.8795         -0.861801  \n",
       "2023-12-29 03:30:00    -0.9905         -0.966176  \n",
       "2023-12-29 03:40:00    -1.0927         -1.080737  \n",
       "...                        ...               ...  \n",
       "2023-12-31 23:10:00     0.3508          0.360075  \n",
       "2023-12-31 23:20:00     0.4242          0.413450  \n",
       "2023-12-31 23:30:00     0.4790          0.486030  \n",
       "2023-12-31 23:40:00     0.5506          0.533500  \n",
       "2023-12-31 23:50:00     0.5865          0.617664  \n",
       "\n",
       "[414 rows x 27 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prediction = exp.predict_model(best_model, data=compare_data)\n",
    "compare_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_48fd2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_48fd2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_48fd2_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_48fd2_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_48fd2_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_48fd2_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_48fd2_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_48fd2_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_48fd2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_48fd2_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_48fd2_row0_col1\" class=\"data row0 col1\" >0.0153</td>\n",
       "      <td id=\"T_48fd2_row0_col2\" class=\"data row0 col2\" >0.0009</td>\n",
       "      <td id=\"T_48fd2_row0_col3\" class=\"data row0 col3\" >0.0308</td>\n",
       "      <td id=\"T_48fd2_row0_col4\" class=\"data row0 col4\" >0.9984</td>\n",
       "      <td id=\"T_48fd2_row0_col5\" class=\"data row0 col5\" >0.0176</td>\n",
       "      <td id=\"T_48fd2_row0_col6\" class=\"data row0 col6\" >0.1002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a851d1410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>moon_phase</th>\n",
       "      <th>full_moon_days</th>\n",
       "      <th>dark_moon_days</th>\n",
       "      <th>W_LEV_AVG_lag_1</th>\n",
       "      <th>W_LEV_AVG_lag_2</th>\n",
       "      <th>W_LEV_AVG_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>W_LEV_AVG_lag_11</th>\n",
       "      <th>W_LEV_AVG_lag_12</th>\n",
       "      <th>W_LEV_AVG_lag_13</th>\n",
       "      <th>W_LEV_AVG_lag_14</th>\n",
       "      <th>W_LEV_AVG_lag_15</th>\n",
       "      <th>W_LEV_AVG_lag_16</th>\n",
       "      <th>W_LEV_AVG_lag_17</th>\n",
       "      <th>W_LEV_AVG_lag_18</th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.4129</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.338574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:10:00</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.283875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:20:00</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.3896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.230873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:30:00</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.163641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01 10:40:00</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.096711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:10:00</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.8404</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.1637</td>\n",
       "      <td>-0.2607</td>\n",
       "      <td>-0.3692</td>\n",
       "      <td>-0.4605</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.918967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:20:00</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.8404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.1637</td>\n",
       "      <td>-0.2607</td>\n",
       "      <td>-0.3692</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.928648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:30:00</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.1637</td>\n",
       "      <td>-0.2607</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.930683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:40:00</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.1637</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.918849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 23:50:00</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.913018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404428 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dayofweek  month  day  hour  moon_phase  full_moon_days  \\\n",
       "DATE                                                                           \n",
       "2013-10-01 10:00:00          1     10    1    10          14               0   \n",
       "2013-10-01 10:10:00          1     10    1    10          14               0   \n",
       "2013-10-01 10:20:00          1     10    1    10          14               0   \n",
       "2013-10-01 10:30:00          1     10    1    10          13               0   \n",
       "2013-10-01 10:40:00          1     10    1    10          13               0   \n",
       "...                        ...    ...  ...   ...         ...             ...   \n",
       "2023-12-28 23:10:00          3     12   28    23          96               0   \n",
       "2023-12-28 23:20:00          3     12   28    23          96               0   \n",
       "2023-12-28 23:30:00          3     12   28    23          96               0   \n",
       "2023-12-28 23:40:00          3     12   28    23          96               0   \n",
       "2023-12-28 23:50:00          3     12   28    23          96               0   \n",
       "\n",
       "                     dark_moon_days  W_LEV_AVG_lag_1  W_LEV_AVG_lag_2  \\\n",
       "DATE                                                                    \n",
       "2013-10-01 10:00:00               0           0.3896           0.4324   \n",
       "2013-10-01 10:10:00               0           0.3375           0.3896   \n",
       "2013-10-01 10:20:00               0           0.2846           0.3375   \n",
       "2013-10-01 10:30:00               0           0.2276           0.2846   \n",
       "2013-10-01 10:40:00               0           0.1704           0.2276   \n",
       "...                             ...              ...              ...   \n",
       "2023-12-28 23:10:00               0           0.8763           0.8404   \n",
       "2023-12-28 23:20:00               0           0.8914           0.8763   \n",
       "2023-12-28 23:30:00               0           0.9097           0.8914   \n",
       "2023-12-28 23:40:00               0           0.9084           0.9097   \n",
       "2023-12-28 23:50:00               0           0.9093           0.9084   \n",
       "\n",
       "                     W_LEV_AVG_lag_3  ...  W_LEV_AVG_lag_11  W_LEV_AVG_lag_12  \\\n",
       "DATE                                  ...                                       \n",
       "2013-10-01 10:00:00           0.4690  ...            0.5791            0.5775   \n",
       "2013-10-01 10:10:00           0.4324  ...            0.5914            0.5791   \n",
       "2013-10-01 10:20:00           0.3896  ...            0.5796            0.5914   \n",
       "2013-10-01 10:30:00           0.3375  ...            0.5802            0.5796   \n",
       "2013-10-01 10:40:00           0.2846  ...            0.5575            0.5802   \n",
       "...                              ...  ...               ...               ...   \n",
       "2023-12-28 23:10:00           0.8163  ...            0.2271            0.1334   \n",
       "2023-12-28 23:20:00           0.8404  ...            0.3083            0.2271   \n",
       "2023-12-28 23:30:00           0.8763  ...            0.3855            0.3083   \n",
       "2023-12-28 23:40:00           0.8914  ...            0.4866            0.3855   \n",
       "2023-12-28 23:50:00           0.9097  ...            0.5650            0.4866   \n",
       "\n",
       "                     W_LEV_AVG_lag_13  W_LEV_AVG_lag_14  W_LEV_AVG_lag_15  \\\n",
       "DATE                                                                        \n",
       "2013-10-01 10:00:00            0.5645            0.5468            0.5079   \n",
       "2013-10-01 10:10:00            0.5775            0.5645            0.5468   \n",
       "2013-10-01 10:20:00            0.5791            0.5775            0.5645   \n",
       "2013-10-01 10:30:00            0.5914            0.5791            0.5775   \n",
       "2013-10-01 10:40:00            0.5796            0.5914            0.5791   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-28 23:10:00            0.0397           -0.0572           -0.1637   \n",
       "2023-12-28 23:20:00            0.1334            0.0397           -0.0572   \n",
       "2023-12-28 23:30:00            0.2271            0.1334            0.0397   \n",
       "2023-12-28 23:40:00            0.3083            0.2271            0.1334   \n",
       "2023-12-28 23:50:00            0.3855            0.3083            0.2271   \n",
       "\n",
       "                     W_LEV_AVG_lag_16  W_LEV_AVG_lag_17  W_LEV_AVG_lag_18  \\\n",
       "DATE                                                                        \n",
       "2013-10-01 10:00:00            0.4901            0.4528            0.4129   \n",
       "2013-10-01 10:10:00            0.5079            0.4901            0.4528   \n",
       "2013-10-01 10:20:00            0.5468            0.5079            0.4901   \n",
       "2013-10-01 10:30:00            0.5645            0.5468            0.5079   \n",
       "2013-10-01 10:40:00            0.5775            0.5645            0.5468   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-28 23:10:00           -0.2607           -0.3692           -0.4605   \n",
       "2023-12-28 23:20:00           -0.1637           -0.2607           -0.3692   \n",
       "2023-12-28 23:30:00           -0.0572           -0.1637           -0.2607   \n",
       "2023-12-28 23:40:00            0.0397           -0.0572           -0.1637   \n",
       "2023-12-28 23:50:00            0.1334            0.0397           -0.0572   \n",
       "\n",
       "                     W_LEV_AVG  prediction_label  \n",
       "DATE                                              \n",
       "2013-10-01 10:00:00     0.3375          0.338574  \n",
       "2013-10-01 10:10:00     0.2846          0.283875  \n",
       "2013-10-01 10:20:00     0.2276          0.230873  \n",
       "2013-10-01 10:30:00     0.1704          0.163641  \n",
       "2013-10-01 10:40:00     0.1157          0.096711  \n",
       "...                        ...               ...  \n",
       "2023-12-28 23:10:00     0.8914          0.918967  \n",
       "2023-12-28 23:20:00     0.9097          0.928648  \n",
       "2023-12-28 23:30:00     0.9084          0.930683  \n",
       "2023-12-28 23:40:00     0.9093          0.918849  \n",
       "2023-12-28 23:50:00     0.8893          0.913018  \n",
       "\n",
       "[404428 rows x 27 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = exp.predict_model(best_model, data=df)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(best_model, plot='learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(best_model, plot='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เทสกับข้อมูลอื่นในหลัก 10 นาที 1 ชั่วโมง และ 1 วันตามลำดับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-22 07:00:00</th>\n",
       "      <td>-0.7662</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-22 07:10:00</th>\n",
       "      <td>-0.7625</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-22 07:20:00</th>\n",
       "      <td>-0.7778</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-22 07:30:00</th>\n",
       "      <td>-0.8250</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-22 07:40:00</th>\n",
       "      <td>-0.8593</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:10:00</th>\n",
       "      <td>-0.3997</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:20:00</th>\n",
       "      <td>-0.3979</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:30:00</th>\n",
       "      <td>-0.3970</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:40:00</th>\n",
       "      <td>-0.3987</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:50:00</th>\n",
       "      <td>-0.4067</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391494 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     W_LEV_AVG  dayofweek  month  day  hour\n",
       "DATE                                                       \n",
       "2016-07-22 07:00:00    -0.7662          4      7   22     7\n",
       "2016-07-22 07:10:00    -0.7625          4      7   22     7\n",
       "2016-07-22 07:20:00    -0.7778          4      7   22     7\n",
       "2016-07-22 07:30:00    -0.8250          4      7   22     7\n",
       "2016-07-22 07:40:00    -0.8593          4      7   22     7\n",
       "...                        ...        ...    ...  ...   ...\n",
       "2023-12-31 23:10:00    -0.3997          6     12   31    23\n",
       "2023-12-31 23:20:00    -0.3979          6     12   31    23\n",
       "2023-12-31 23:30:00    -0.3970          6     12   31    23\n",
       "2023-12-31 23:40:00    -0.3987          6     12   31    23\n",
       "2023-12-31 23:50:00    -0.4067          6     12   31    23\n",
       "\n",
       "[391494 rows x 5 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.regression import *\n",
    "# W_LEV_AVG\t= ค่าระดับน้ำทะเล หน่วยเมตร\n",
    "# Load your dataset\n",
    "df_test = pd.read_csv(\"data_preprocess/raw_data/dmr_tidal-level-chompon-tidegauge-2016_2023.csv\")\n",
    "# ลบช่องว่างเกินออก (กันกรณีมี space แปลก ๆ)\n",
    "df_test[\"DATE\"] = df_test[\"DATE\"].str.strip()\n",
    "\n",
    "# เติมเลข 0 ให้ชั่วโมงหลักเดียว และเติม \":00\" ถ้าขาดวินาที\n",
    "df_test[\"DATE\"] = df_test[\"DATE\"].str.replace(r\"(\\d{1,2}/\\d{1,2}/\\d{4}) (\\d{1}):(\\d{2})$\", r\"\\1 0\\2:\\3:00\", regex=True)\n",
    "df_test[\"DATE\"] = df_test[\"DATE\"].str.replace(r\"(\\d{1,2}/\\d{1,2}/\\d{4}) (\\d{2}:\\d{2})$\", r\"\\1 \\2:00\", regex=True)\n",
    "\n",
    "# แปลงเป็น datetime โดยกำหนด dayfirst=True\n",
    "df_test[\"DATE\"] = pd.to_datetime(df_test[\"DATE\"], format=\"%d/%m/%Y %H:%M:%S\", dayfirst=True)\n",
    "df_test.set_index('DATE', inplace=True)\n",
    "df_test['dayofweek'] = df_test.index.dayofweek\n",
    "df_test['month'] = df_test.index.month\n",
    "df_test['day'] = df_test.index.day\n",
    "df_test['hour'] = df_test.index.hour\n",
    "df_test = df_test.drop(columns=[\"TW_ID\", \"TW_NAME\", \"UTM_E\", 'UTM_N'], axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ฟังก์ชันหาข้างขึ้นข้างแรม\n",
    "def get_moon_phase(dt):\n",
    "    moon_phase = ephem.Moon(dt).phase  # คำนวณเฟสของดวงจันทร์\n",
    "    return round(moon_phase)  # ปัดค่า phase ให้เป็นจำนวนเต็ม (0-29)\n",
    "\n",
    "# คำนวณข้างขึ้นข้างแรม และเพิ่มเป็นคอลัมน์ใหม่\n",
    "df_test[\"moon_phase\"] = df_test.index.to_series().apply(get_moon_phase)\n",
    "\n",
    "# เพิ่มคอลัมน์ full_moon_days (ขึ้น 15 ค่ำ) และ dark_moon_days (แรม 15 ค่ำ)\n",
    "df_test[\"full_moon_days\"] = (df_test[\"moon_phase\"] == 15).astype(int) #(ขึ้น 15 ค่ำ)\n",
    "df_test[\"dark_moon_days\"] = (df_test[\"moon_phase\"] == 29).astype(int) #(แรม 15 ค่ำ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for the past 14 days\n",
    "for lag in range(1, 19):  # Lags from 1 to 14 days\n",
    "    df_test[f'W_LEV_AVG_lag_{lag}'] = df_test['W_LEV_AVG'].shift(lag)\n",
    "\n",
    "# Drop NaN values caused by shifting\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d45a5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d45a5_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d45a5_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_d45a5_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_d45a5_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_d45a5_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_d45a5_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_d45a5_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d45a5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d45a5_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_d45a5_row0_col1\" class=\"data row0 col1\" >0.0288</td>\n",
       "      <td id=\"T_d45a5_row0_col2\" class=\"data row0 col2\" >0.0012</td>\n",
       "      <td id=\"T_d45a5_row0_col3\" class=\"data row0 col3\" >0.0346</td>\n",
       "      <td id=\"T_d45a5_row0_col4\" class=\"data row0 col4\" >0.9949</td>\n",
       "      <td id=\"T_d45a5_row0_col5\" class=\"data row0 col5\" >0.0241</td>\n",
       "      <td id=\"T_d45a5_row0_col6\" class=\"data row0 col6\" >0.3752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a985df510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>moon_phase</th>\n",
       "      <th>full_moon_days</th>\n",
       "      <th>dark_moon_days</th>\n",
       "      <th>W_LEV_AVG_lag_1</th>\n",
       "      <th>W_LEV_AVG_lag_2</th>\n",
       "      <th>W_LEV_AVG_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>W_LEV_AVG_lag_11</th>\n",
       "      <th>W_LEV_AVG_lag_12</th>\n",
       "      <th>W_LEV_AVG_lag_13</th>\n",
       "      <th>W_LEV_AVG_lag_14</th>\n",
       "      <th>W_LEV_AVG_lag_15</th>\n",
       "      <th>W_LEV_AVG_lag_16</th>\n",
       "      <th>W_LEV_AVG_lag_17</th>\n",
       "      <th>W_LEV_AVG_lag_18</th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-22 10:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.9173</td>\n",
       "      <td>-0.9125</td>\n",
       "      <td>-0.8918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8674</td>\n",
       "      <td>-0.8717</td>\n",
       "      <td>-0.8612</td>\n",
       "      <td>-0.8593</td>\n",
       "      <td>-0.8250</td>\n",
       "      <td>-0.7778</td>\n",
       "      <td>-0.7625</td>\n",
       "      <td>-0.7662</td>\n",
       "      <td>-0.8955</td>\n",
       "      <td>-0.865916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-22 10:10:00</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8955</td>\n",
       "      <td>-0.9173</td>\n",
       "      <td>-0.9125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8855</td>\n",
       "      <td>-0.8674</td>\n",
       "      <td>-0.8717</td>\n",
       "      <td>-0.8612</td>\n",
       "      <td>-0.8593</td>\n",
       "      <td>-0.8250</td>\n",
       "      <td>-0.7778</td>\n",
       "      <td>-0.7625</td>\n",
       "      <td>-0.8758</td>\n",
       "      <td>-0.840880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-22 10:20:00</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8758</td>\n",
       "      <td>-0.8955</td>\n",
       "      <td>-0.9173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8969</td>\n",
       "      <td>-0.8855</td>\n",
       "      <td>-0.8674</td>\n",
       "      <td>-0.8717</td>\n",
       "      <td>-0.8612</td>\n",
       "      <td>-0.8593</td>\n",
       "      <td>-0.8250</td>\n",
       "      <td>-0.7778</td>\n",
       "      <td>-0.8768</td>\n",
       "      <td>-0.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-22 10:30:00</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8768</td>\n",
       "      <td>-0.8758</td>\n",
       "      <td>-0.8955</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8944</td>\n",
       "      <td>-0.8969</td>\n",
       "      <td>-0.8855</td>\n",
       "      <td>-0.8674</td>\n",
       "      <td>-0.8717</td>\n",
       "      <td>-0.8612</td>\n",
       "      <td>-0.8593</td>\n",
       "      <td>-0.8250</td>\n",
       "      <td>-0.8683</td>\n",
       "      <td>-0.822869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-22 10:40:00</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.8683</td>\n",
       "      <td>-0.8768</td>\n",
       "      <td>-0.8758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8905</td>\n",
       "      <td>-0.8944</td>\n",
       "      <td>-0.8969</td>\n",
       "      <td>-0.8855</td>\n",
       "      <td>-0.8674</td>\n",
       "      <td>-0.8717</td>\n",
       "      <td>-0.8612</td>\n",
       "      <td>-0.8593</td>\n",
       "      <td>-0.8604</td>\n",
       "      <td>-0.809049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:10:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3997</td>\n",
       "      <td>-0.3846</td>\n",
       "      <td>-0.3797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2651</td>\n",
       "      <td>-0.2469</td>\n",
       "      <td>-0.2201</td>\n",
       "      <td>-0.1949</td>\n",
       "      <td>-0.1731</td>\n",
       "      <td>-0.1539</td>\n",
       "      <td>-0.1355</td>\n",
       "      <td>-0.1111</td>\n",
       "      <td>-0.3997</td>\n",
       "      <td>-0.421837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:20:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3997</td>\n",
       "      <td>-0.3997</td>\n",
       "      <td>-0.3846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2803</td>\n",
       "      <td>-0.2651</td>\n",
       "      <td>-0.2469</td>\n",
       "      <td>-0.2201</td>\n",
       "      <td>-0.1949</td>\n",
       "      <td>-0.1731</td>\n",
       "      <td>-0.1539</td>\n",
       "      <td>-0.1355</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-0.421837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:30:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-0.3997</td>\n",
       "      <td>-0.3997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3030</td>\n",
       "      <td>-0.2803</td>\n",
       "      <td>-0.2651</td>\n",
       "      <td>-0.2469</td>\n",
       "      <td>-0.2201</td>\n",
       "      <td>-0.1949</td>\n",
       "      <td>-0.1731</td>\n",
       "      <td>-0.1539</td>\n",
       "      <td>-0.3970</td>\n",
       "      <td>-0.410639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:40:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3970</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>-0.3997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.3030</td>\n",
       "      <td>-0.2803</td>\n",
       "      <td>-0.2651</td>\n",
       "      <td>-0.2469</td>\n",
       "      <td>-0.2201</td>\n",
       "      <td>-0.1949</td>\n",
       "      <td>-0.1731</td>\n",
       "      <td>-0.3987</td>\n",
       "      <td>-0.410639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:50:00</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3987</td>\n",
       "      <td>-0.3970</td>\n",
       "      <td>-0.3979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3388</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.3030</td>\n",
       "      <td>-0.2803</td>\n",
       "      <td>-0.2651</td>\n",
       "      <td>-0.2469</td>\n",
       "      <td>-0.2201</td>\n",
       "      <td>-0.1949</td>\n",
       "      <td>-0.4067</td>\n",
       "      <td>-0.400160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291452 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dayofweek  month  day  hour  moon_phase  full_moon_days  \\\n",
       "DATE                                                                           \n",
       "2016-07-22 10:00:00          4      7   22    10          93               0   \n",
       "2016-07-22 10:10:00          4      7   22    10          93               0   \n",
       "2016-07-22 10:20:00          4      7   22    10          93               0   \n",
       "2016-07-22 10:30:00          4      7   22    10          93               0   \n",
       "2016-07-22 10:40:00          4      7   22    10          93               0   \n",
       "...                        ...    ...  ...   ...         ...             ...   \n",
       "2023-12-31 23:10:00          6     12   31    23          78               0   \n",
       "2023-12-31 23:20:00          6     12   31    23          78               0   \n",
       "2023-12-31 23:30:00          6     12   31    23          78               0   \n",
       "2023-12-31 23:40:00          6     12   31    23          78               0   \n",
       "2023-12-31 23:50:00          6     12   31    23          78               0   \n",
       "\n",
       "                     dark_moon_days  W_LEV_AVG_lag_1  W_LEV_AVG_lag_2  \\\n",
       "DATE                                                                    \n",
       "2016-07-22 10:00:00               0          -0.9173          -0.9125   \n",
       "2016-07-22 10:10:00               0          -0.8955          -0.9173   \n",
       "2016-07-22 10:20:00               0          -0.8758          -0.8955   \n",
       "2016-07-22 10:30:00               0          -0.8768          -0.8758   \n",
       "2016-07-22 10:40:00               0          -0.8683          -0.8768   \n",
       "...                             ...              ...              ...   \n",
       "2023-12-31 23:10:00               0          -0.3997          -0.3846   \n",
       "2023-12-31 23:20:00               0          -0.3997          -0.3997   \n",
       "2023-12-31 23:30:00               0          -0.3979          -0.3997   \n",
       "2023-12-31 23:40:00               0          -0.3970          -0.3979   \n",
       "2023-12-31 23:50:00               0          -0.3987          -0.3970   \n",
       "\n",
       "                     W_LEV_AVG_lag_3  ...  W_LEV_AVG_lag_11  W_LEV_AVG_lag_12  \\\n",
       "DATE                                  ...                                       \n",
       "2016-07-22 10:00:00          -0.8918  ...           -0.8674           -0.8717   \n",
       "2016-07-22 10:10:00          -0.9125  ...           -0.8855           -0.8674   \n",
       "2016-07-22 10:20:00          -0.9173  ...           -0.8969           -0.8855   \n",
       "2016-07-22 10:30:00          -0.8955  ...           -0.8944           -0.8969   \n",
       "2016-07-22 10:40:00          -0.8758  ...           -0.8905           -0.8944   \n",
       "...                              ...  ...               ...               ...   \n",
       "2023-12-31 23:10:00          -0.3797  ...           -0.2651           -0.2469   \n",
       "2023-12-31 23:20:00          -0.3846  ...           -0.2803           -0.2651   \n",
       "2023-12-31 23:30:00          -0.3997  ...           -0.3030           -0.2803   \n",
       "2023-12-31 23:40:00          -0.3997  ...           -0.3195           -0.3030   \n",
       "2023-12-31 23:50:00          -0.3979  ...           -0.3388           -0.3195   \n",
       "\n",
       "                     W_LEV_AVG_lag_13  W_LEV_AVG_lag_14  W_LEV_AVG_lag_15  \\\n",
       "DATE                                                                        \n",
       "2016-07-22 10:00:00           -0.8612           -0.8593           -0.8250   \n",
       "2016-07-22 10:10:00           -0.8717           -0.8612           -0.8593   \n",
       "2016-07-22 10:20:00           -0.8674           -0.8717           -0.8612   \n",
       "2016-07-22 10:30:00           -0.8855           -0.8674           -0.8717   \n",
       "2016-07-22 10:40:00           -0.8969           -0.8855           -0.8674   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-31 23:10:00           -0.2201           -0.1949           -0.1731   \n",
       "2023-12-31 23:20:00           -0.2469           -0.2201           -0.1949   \n",
       "2023-12-31 23:30:00           -0.2651           -0.2469           -0.2201   \n",
       "2023-12-31 23:40:00           -0.2803           -0.2651           -0.2469   \n",
       "2023-12-31 23:50:00           -0.3030           -0.2803           -0.2651   \n",
       "\n",
       "                     W_LEV_AVG_lag_16  W_LEV_AVG_lag_17  W_LEV_AVG_lag_18  \\\n",
       "DATE                                                                        \n",
       "2016-07-22 10:00:00           -0.7778           -0.7625           -0.7662   \n",
       "2016-07-22 10:10:00           -0.8250           -0.7778           -0.7625   \n",
       "2016-07-22 10:20:00           -0.8593           -0.8250           -0.7778   \n",
       "2016-07-22 10:30:00           -0.8612           -0.8593           -0.8250   \n",
       "2016-07-22 10:40:00           -0.8717           -0.8612           -0.8593   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-31 23:10:00           -0.1539           -0.1355           -0.1111   \n",
       "2023-12-31 23:20:00           -0.1731           -0.1539           -0.1355   \n",
       "2023-12-31 23:30:00           -0.1949           -0.1731           -0.1539   \n",
       "2023-12-31 23:40:00           -0.2201           -0.1949           -0.1731   \n",
       "2023-12-31 23:50:00           -0.2469           -0.2201           -0.1949   \n",
       "\n",
       "                     W_LEV_AVG  prediction_label  \n",
       "DATE                                              \n",
       "2016-07-22 10:00:00    -0.8955         -0.865916  \n",
       "2016-07-22 10:10:00    -0.8758         -0.840880  \n",
       "2016-07-22 10:20:00    -0.8768         -0.822869  \n",
       "2016-07-22 10:30:00    -0.8683         -0.822869  \n",
       "2016-07-22 10:40:00    -0.8604         -0.809049  \n",
       "...                        ...               ...  \n",
       "2023-12-31 23:10:00    -0.3997         -0.421837  \n",
       "2023-12-31 23:20:00    -0.3979         -0.421837  \n",
       "2023-12-31 23:30:00    -0.3970         -0.410639  \n",
       "2023-12-31 23:40:00    -0.3987         -0.410639  \n",
       "2023-12-31 23:50:00    -0.4067         -0.400160  \n",
       "\n",
       "[291452 rows x 27 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction_m = exp.predict_model(best_model, data=df_test)\n",
    "test_prediction_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0cc53\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0cc53_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_0cc53_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_0cc53_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_0cc53_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_0cc53_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_0cc53_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_0cc53_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0cc53_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0cc53_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_0cc53_row0_col1\" class=\"data row0 col1\" >0.1092</td>\n",
       "      <td id=\"T_0cc53_row0_col2\" class=\"data row0 col2\" >0.0173</td>\n",
       "      <td id=\"T_0cc53_row0_col3\" class=\"data row0 col3\" >0.1314</td>\n",
       "      <td id=\"T_0cc53_row0_col4\" class=\"data row0 col4\" >0.9257</td>\n",
       "      <td id=\"T_0cc53_row0_col5\" class=\"data row0 col5\" >0.0899</td>\n",
       "      <td id=\"T_0cc53_row0_col6\" class=\"data row0 col6\" >2.0468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17ae0c7a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>moon_phase</th>\n",
       "      <th>full_moon_days</th>\n",
       "      <th>dark_moon_days</th>\n",
       "      <th>W_LEV_AVG_lag_1</th>\n",
       "      <th>W_LEV_AVG_lag_2</th>\n",
       "      <th>W_LEV_AVG_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>W_LEV_AVG_lag_11</th>\n",
       "      <th>W_LEV_AVG_lag_12</th>\n",
       "      <th>W_LEV_AVG_lag_13</th>\n",
       "      <th>W_LEV_AVG_lag_14</th>\n",
       "      <th>W_LEV_AVG_lag_15</th>\n",
       "      <th>W_LEV_AVG_lag_16</th>\n",
       "      <th>W_LEV_AVG_lag_17</th>\n",
       "      <th>W_LEV_AVG_lag_18</th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-23 04:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307333</td>\n",
       "      <td>0.509617</td>\n",
       "      <td>0.637950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425967</td>\n",
       "      <td>-0.506700</td>\n",
       "      <td>-0.571750</td>\n",
       "      <td>-0.638933</td>\n",
       "      <td>-0.717783</td>\n",
       "      <td>-0.792517</td>\n",
       "      <td>-0.823017</td>\n",
       "      <td>-0.871017</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.296895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-23 05:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.307333</td>\n",
       "      <td>0.509617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328733</td>\n",
       "      <td>-0.425967</td>\n",
       "      <td>-0.506700</td>\n",
       "      <td>-0.571750</td>\n",
       "      <td>-0.638933</td>\n",
       "      <td>-0.717783</td>\n",
       "      <td>-0.792517</td>\n",
       "      <td>-0.823017</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>-0.080451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-23 06:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.166664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.307333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196950</td>\n",
       "      <td>-0.328733</td>\n",
       "      <td>-0.425967</td>\n",
       "      <td>-0.506700</td>\n",
       "      <td>-0.571750</td>\n",
       "      <td>-0.638933</td>\n",
       "      <td>-0.717783</td>\n",
       "      <td>-0.792517</td>\n",
       "      <td>-0.454333</td>\n",
       "      <td>-0.379808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-23 07:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.454333</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016017</td>\n",
       "      <td>-0.196950</td>\n",
       "      <td>-0.328733</td>\n",
       "      <td>-0.425967</td>\n",
       "      <td>-0.506700</td>\n",
       "      <td>-0.571750</td>\n",
       "      <td>-0.638933</td>\n",
       "      <td>-0.717783</td>\n",
       "      <td>-0.614567</td>\n",
       "      <td>-0.390166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-23 08:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.614567</td>\n",
       "      <td>-0.454333</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214950</td>\n",
       "      <td>-0.016017</td>\n",
       "      <td>-0.196950</td>\n",
       "      <td>-0.328733</td>\n",
       "      <td>-0.425967</td>\n",
       "      <td>-0.506700</td>\n",
       "      <td>-0.571750</td>\n",
       "      <td>-0.638933</td>\n",
       "      <td>-0.744100</td>\n",
       "      <td>-0.504012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 19:00:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256650</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>0.759050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.064233</td>\n",
       "      <td>-0.052000</td>\n",
       "      <td>-0.140717</td>\n",
       "      <td>-0.209483</td>\n",
       "      <td>-0.271000</td>\n",
       "      <td>-0.344250</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>-0.024557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 20:00:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.256650</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.064233</td>\n",
       "      <td>-0.052000</td>\n",
       "      <td>-0.140717</td>\n",
       "      <td>-0.209483</td>\n",
       "      <td>-0.271000</td>\n",
       "      <td>-0.141900</td>\n",
       "      <td>-0.050149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 21:00:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.141900</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.256650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.064233</td>\n",
       "      <td>-0.052000</td>\n",
       "      <td>-0.140717</td>\n",
       "      <td>-0.209483</td>\n",
       "      <td>-0.272483</td>\n",
       "      <td>-0.241888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 22:00:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>78.666664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272483</td>\n",
       "      <td>-0.141900</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.094383</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.064233</td>\n",
       "      <td>-0.052000</td>\n",
       "      <td>-0.140717</td>\n",
       "      <td>-0.366000</td>\n",
       "      <td>-0.313133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:00:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.366000</td>\n",
       "      <td>-0.272483</td>\n",
       "      <td>-0.141900</td>\n",
       "      <td>...</td>\n",
       "      <td>1.234800</td>\n",
       "      <td>1.094383</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.408083</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.064233</td>\n",
       "      <td>-0.052000</td>\n",
       "      <td>-0.399950</td>\n",
       "      <td>-0.364088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48592 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dayofweek  month   day  hour  moon_phase  full_moon_days  \\\n",
       "DATE                                                                            \n",
       "2016-07-23 04:00:00        5.0    7.0  23.0   4.0   88.000000             0.0   \n",
       "2016-07-23 05:00:00        5.0    7.0  23.0   5.0   88.000000             0.0   \n",
       "2016-07-23 06:00:00        5.0    7.0  23.0   6.0   87.166664             0.0   \n",
       "2016-07-23 07:00:00        5.0    7.0  23.0   7.0   87.000000             0.0   \n",
       "2016-07-23 08:00:00        5.0    7.0  23.0   8.0   87.000000             0.0   \n",
       "...                        ...    ...   ...   ...         ...             ...   \n",
       "2023-12-31 19:00:00        6.0   12.0  31.0  19.0   79.500000             0.0   \n",
       "2023-12-31 20:00:00        6.0   12.0  31.0  20.0   79.000000             0.0   \n",
       "2023-12-31 21:00:00        6.0   12.0  31.0  21.0   79.000000             0.0   \n",
       "2023-12-31 22:00:00        6.0   12.0  31.0  22.0   78.666664             0.0   \n",
       "2023-12-31 23:00:00        6.0   12.0  31.0  23.0   78.000000             0.0   \n",
       "\n",
       "                     dark_moon_days  W_LEV_AVG_lag_1  W_LEV_AVG_lag_2  \\\n",
       "DATE                                                                    \n",
       "2016-07-23 04:00:00             0.0         0.307333         0.509617   \n",
       "2016-07-23 05:00:00             0.0         0.021067         0.307333   \n",
       "2016-07-23 06:00:00             0.0        -0.226000         0.021067   \n",
       "2016-07-23 07:00:00             0.0        -0.454333        -0.226000   \n",
       "2016-07-23 08:00:00             0.0        -0.614567        -0.454333   \n",
       "...                             ...              ...              ...   \n",
       "2023-12-31 19:00:00             0.0         0.256650         0.498333   \n",
       "2023-12-31 20:00:00             0.0         0.036850         0.256650   \n",
       "2023-12-31 21:00:00             0.0        -0.141900         0.036850   \n",
       "2023-12-31 22:00:00             0.0        -0.272483        -0.141900   \n",
       "2023-12-31 23:00:00             0.0        -0.366000        -0.272483   \n",
       "\n",
       "                     W_LEV_AVG_lag_3  ...  W_LEV_AVG_lag_11  W_LEV_AVG_lag_12  \\\n",
       "DATE                                  ...                                       \n",
       "2016-07-23 04:00:00         0.637950  ...         -0.425967         -0.506700   \n",
       "2016-07-23 05:00:00         0.509617  ...         -0.328733         -0.425967   \n",
       "2016-07-23 06:00:00         0.307333  ...         -0.196950         -0.328733   \n",
       "2016-07-23 07:00:00         0.021067  ...         -0.016017         -0.196950   \n",
       "2016-07-23 08:00:00        -0.226000  ...          0.214950         -0.016017   \n",
       "...                              ...  ...               ...               ...   \n",
       "2023-12-31 19:00:00         0.759050  ...          0.408083          0.209600   \n",
       "2023-12-31 20:00:00         0.498333  ...          0.642400          0.408083   \n",
       "2023-12-31 21:00:00         0.256650  ...          0.889250          0.642400   \n",
       "2023-12-31 22:00:00         0.036850  ...          1.094383          0.889250   \n",
       "2023-12-31 23:00:00        -0.141900  ...          1.234800          1.094383   \n",
       "\n",
       "                     W_LEV_AVG_lag_13  W_LEV_AVG_lag_14  W_LEV_AVG_lag_15  \\\n",
       "DATE                                                                        \n",
       "2016-07-23 04:00:00         -0.571750         -0.638933         -0.717783   \n",
       "2016-07-23 05:00:00         -0.506700         -0.571750         -0.638933   \n",
       "2016-07-23 06:00:00         -0.425967         -0.506700         -0.571750   \n",
       "2016-07-23 07:00:00         -0.328733         -0.425967         -0.506700   \n",
       "2016-07-23 08:00:00         -0.196950         -0.328733         -0.425967   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-31 19:00:00          0.064233         -0.052000         -0.140717   \n",
       "2023-12-31 20:00:00          0.209600          0.064233         -0.052000   \n",
       "2023-12-31 21:00:00          0.408083          0.209600          0.064233   \n",
       "2023-12-31 22:00:00          0.642400          0.408083          0.209600   \n",
       "2023-12-31 23:00:00          0.889250          0.642400          0.408083   \n",
       "\n",
       "                     W_LEV_AVG_lag_16  W_LEV_AVG_lag_17  W_LEV_AVG_lag_18  \\\n",
       "DATE                                                                        \n",
       "2016-07-23 04:00:00         -0.792517         -0.823017         -0.871017   \n",
       "2016-07-23 05:00:00         -0.717783         -0.792517         -0.823017   \n",
       "2016-07-23 06:00:00         -0.638933         -0.717783         -0.792517   \n",
       "2016-07-23 07:00:00         -0.571750         -0.638933         -0.717783   \n",
       "2016-07-23 08:00:00         -0.506700         -0.571750         -0.638933   \n",
       "...                               ...               ...               ...   \n",
       "2023-12-31 19:00:00         -0.209483         -0.271000         -0.344250   \n",
       "2023-12-31 20:00:00         -0.140717         -0.209483         -0.271000   \n",
       "2023-12-31 21:00:00         -0.052000         -0.140717         -0.209483   \n",
       "2023-12-31 22:00:00          0.064233         -0.052000         -0.140717   \n",
       "2023-12-31 23:00:00          0.209600          0.064233         -0.052000   \n",
       "\n",
       "                     W_LEV_AVG  prediction_label  \n",
       "DATE                                              \n",
       "2016-07-23 04:00:00   0.021067          0.296895  \n",
       "2016-07-23 05:00:00  -0.226000         -0.080451  \n",
       "2016-07-23 06:00:00  -0.454333         -0.379808  \n",
       "2016-07-23 07:00:00  -0.614567         -0.390166  \n",
       "2016-07-23 08:00:00  -0.744100         -0.504012  \n",
       "...                        ...               ...  \n",
       "2023-12-31 19:00:00   0.036850         -0.024557  \n",
       "2023-12-31 20:00:00  -0.141900         -0.050149  \n",
       "2023-12-31 21:00:00  -0.272483         -0.241888  \n",
       "2023-12-31 22:00:00  -0.366000         -0.313133  \n",
       "2023-12-31 23:00:00  -0.399950         -0.364088  \n",
       "\n",
       "[48592 rows x 27 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_h = df_test.resample(\"h\").mean()\n",
    "df_test_h.dropna(inplace=True)\n",
    "\n",
    "# Create lag features for the past 14 days\n",
    "for lag in range(1, 19):  # Lags from 1 to 14 days\n",
    "    df_test_h[f'W_LEV_AVG_lag_{lag}'] = df_test_h['W_LEV_AVG'].shift(lag)\n",
    "df_test_h.dropna(inplace=True)\n",
    "\n",
    "test_prediction_h = exp.predict_model(best_model, data=df_test_h)\n",
    "test_prediction_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3b295\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3b295_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3b295_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_3b295_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_3b295_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_3b295_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_3b295_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_3b295_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3b295_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3b295_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_3b295_row0_col1\" class=\"data row0 col1\" >0.0826</td>\n",
       "      <td id=\"T_3b295_row0_col2\" class=\"data row0 col2\" >0.0132</td>\n",
       "      <td id=\"T_3b295_row0_col3\" class=\"data row0 col3\" >0.1149</td>\n",
       "      <td id=\"T_3b295_row0_col4\" class=\"data row0 col4\" >0.7711</td>\n",
       "      <td id=\"T_3b295_row0_col5\" class=\"data row0 col5\" >0.0837</td>\n",
       "      <td id=\"T_3b295_row0_col6\" class=\"data row0 col6\" >1.6573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a9cbdb710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>moon_phase</th>\n",
       "      <th>full_moon_days</th>\n",
       "      <th>dark_moon_days</th>\n",
       "      <th>W_LEV_AVG_lag_1</th>\n",
       "      <th>W_LEV_AVG_lag_2</th>\n",
       "      <th>W_LEV_AVG_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>W_LEV_AVG_lag_11</th>\n",
       "      <th>W_LEV_AVG_lag_12</th>\n",
       "      <th>W_LEV_AVG_lag_13</th>\n",
       "      <th>W_LEV_AVG_lag_14</th>\n",
       "      <th>W_LEV_AVG_lag_15</th>\n",
       "      <th>W_LEV_AVG_lag_16</th>\n",
       "      <th>W_LEV_AVG_lag_17</th>\n",
       "      <th>W_LEV_AVG_lag_18</th>\n",
       "      <th>W_LEV_AVG</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-08-09</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>38.215279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.435174</td>\n",
       "      <td>-0.461972</td>\n",
       "      <td>-0.357922</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>-0.288399</td>\n",
       "      <td>-0.335149</td>\n",
       "      <td>-0.416648</td>\n",
       "      <td>-0.262940</td>\n",
       "      <td>-0.347915</td>\n",
       "      <td>-0.269145</td>\n",
       "      <td>-0.333580</td>\n",
       "      <td>-0.404411</td>\n",
       "      <td>-0.417766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>47.583332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.404411</td>\n",
       "      <td>-0.435174</td>\n",
       "      <td>-0.461972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347185</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>-0.288399</td>\n",
       "      <td>-0.335149</td>\n",
       "      <td>-0.416648</td>\n",
       "      <td>-0.262940</td>\n",
       "      <td>-0.347915</td>\n",
       "      <td>-0.269145</td>\n",
       "      <td>-0.501238</td>\n",
       "      <td>-0.414057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>57.069443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.501238</td>\n",
       "      <td>-0.404411</td>\n",
       "      <td>-0.435174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374085</td>\n",
       "      <td>-0.347185</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>-0.288399</td>\n",
       "      <td>-0.335149</td>\n",
       "      <td>-0.416648</td>\n",
       "      <td>-0.262940</td>\n",
       "      <td>-0.347915</td>\n",
       "      <td>-0.575842</td>\n",
       "      <td>-0.487823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>66.395836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.575842</td>\n",
       "      <td>-0.501238</td>\n",
       "      <td>-0.404411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472896</td>\n",
       "      <td>-0.374085</td>\n",
       "      <td>-0.347185</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>-0.288399</td>\n",
       "      <td>-0.335149</td>\n",
       "      <td>-0.416648</td>\n",
       "      <td>-0.262940</td>\n",
       "      <td>-0.452125</td>\n",
       "      <td>-0.553355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>75.236115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.452125</td>\n",
       "      <td>-0.575842</td>\n",
       "      <td>-0.501238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560056</td>\n",
       "      <td>-0.472896</td>\n",
       "      <td>-0.374085</td>\n",
       "      <td>-0.347185</td>\n",
       "      <td>-0.343085</td>\n",
       "      <td>-0.288399</td>\n",
       "      <td>-0.335149</td>\n",
       "      <td>-0.416648</td>\n",
       "      <td>-0.503794</td>\n",
       "      <td>-0.459493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>99.576385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.610687</td>\n",
       "      <td>0.538469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255712</td>\n",
       "      <td>0.264506</td>\n",
       "      <td>0.315138</td>\n",
       "      <td>0.280124</td>\n",
       "      <td>0.270866</td>\n",
       "      <td>0.200095</td>\n",
       "      <td>0.182337</td>\n",
       "      <td>0.212726</td>\n",
       "      <td>0.479415</td>\n",
       "      <td>0.629889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>97.548615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.479415</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.610687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405360</td>\n",
       "      <td>0.255712</td>\n",
       "      <td>0.264506</td>\n",
       "      <td>0.315138</td>\n",
       "      <td>0.280124</td>\n",
       "      <td>0.270866</td>\n",
       "      <td>0.200095</td>\n",
       "      <td>0.182337</td>\n",
       "      <td>0.411685</td>\n",
       "      <td>0.391010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>93.798615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411685</td>\n",
       "      <td>0.479415</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452292</td>\n",
       "      <td>0.405360</td>\n",
       "      <td>0.255712</td>\n",
       "      <td>0.264506</td>\n",
       "      <td>0.315138</td>\n",
       "      <td>0.280124</td>\n",
       "      <td>0.270866</td>\n",
       "      <td>0.200095</td>\n",
       "      <td>0.377428</td>\n",
       "      <td>0.369154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>88.437500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377428</td>\n",
       "      <td>0.411685</td>\n",
       "      <td>0.479415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282938</td>\n",
       "      <td>0.452292</td>\n",
       "      <td>0.405360</td>\n",
       "      <td>0.255712</td>\n",
       "      <td>0.264506</td>\n",
       "      <td>0.315138</td>\n",
       "      <td>0.280124</td>\n",
       "      <td>0.270866</td>\n",
       "      <td>0.399299</td>\n",
       "      <td>0.349285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>81.763885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399299</td>\n",
       "      <td>0.377428</td>\n",
       "      <td>0.411685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297849</td>\n",
       "      <td>0.282938</td>\n",
       "      <td>0.452292</td>\n",
       "      <td>0.405360</td>\n",
       "      <td>0.255712</td>\n",
       "      <td>0.264506</td>\n",
       "      <td>0.315138</td>\n",
       "      <td>0.280124</td>\n",
       "      <td>0.287383</td>\n",
       "      <td>0.371205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2026 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dayofweek  month   day  hour  moon_phase  full_moon_days  \\\n",
       "DATE                                                                   \n",
       "2016-08-09        1.0    8.0   9.0  11.5   38.215279             0.0   \n",
       "2016-08-10        2.0    8.0  10.0  11.5   47.583332             0.0   \n",
       "2016-08-11        3.0    8.0  11.0  11.5   57.069443             0.0   \n",
       "2016-08-12        4.0    8.0  12.0  11.5   66.395836             0.0   \n",
       "2016-08-13        5.0    8.0  13.0  11.5   75.236115             0.0   \n",
       "...               ...    ...   ...   ...         ...             ...   \n",
       "2023-12-27        2.0   12.0  27.0  11.5   99.576385             0.0   \n",
       "2023-12-28        3.0   12.0  28.0  11.5   97.548615             0.0   \n",
       "2023-12-29        4.0   12.0  29.0  11.5   93.798615             0.0   \n",
       "2023-12-30        5.0   12.0  30.0  11.5   88.437500             0.0   \n",
       "2023-12-31        6.0   12.0  31.0  11.5   81.763885             0.0   \n",
       "\n",
       "            dark_moon_days  W_LEV_AVG_lag_1  W_LEV_AVG_lag_2  W_LEV_AVG_lag_3  \\\n",
       "DATE                                                                            \n",
       "2016-08-09             0.0        -0.435174        -0.461972        -0.357922   \n",
       "2016-08-10             0.0        -0.404411        -0.435174        -0.461972   \n",
       "2016-08-11             0.0        -0.501238        -0.404411        -0.435174   \n",
       "2016-08-12             0.0        -0.575842        -0.501238        -0.404411   \n",
       "2016-08-13             0.0        -0.452125        -0.575842        -0.501238   \n",
       "...                    ...              ...              ...              ...   \n",
       "2023-12-27             0.0         0.650602         0.610687         0.538469   \n",
       "2023-12-28             0.0         0.479415         0.650602         0.610687   \n",
       "2023-12-29             0.0         0.411685         0.479415         0.650602   \n",
       "2023-12-30             0.0         0.377428         0.411685         0.479415   \n",
       "2023-12-31             0.0         0.399299         0.377428         0.411685   \n",
       "\n",
       "            ...  W_LEV_AVG_lag_11  W_LEV_AVG_lag_12  W_LEV_AVG_lag_13  \\\n",
       "DATE        ...                                                         \n",
       "2016-08-09  ...         -0.343085         -0.288399         -0.335149   \n",
       "2016-08-10  ...         -0.347185         -0.343085         -0.288399   \n",
       "2016-08-11  ...         -0.374085         -0.347185         -0.343085   \n",
       "2016-08-12  ...         -0.472896         -0.374085         -0.347185   \n",
       "2016-08-13  ...         -0.560056         -0.472896         -0.374085   \n",
       "...         ...               ...               ...               ...   \n",
       "2023-12-27  ...          0.255712          0.264506          0.315138   \n",
       "2023-12-28  ...          0.405360          0.255712          0.264506   \n",
       "2023-12-29  ...          0.452292          0.405360          0.255712   \n",
       "2023-12-30  ...          0.282938          0.452292          0.405360   \n",
       "2023-12-31  ...          0.297849          0.282938          0.452292   \n",
       "\n",
       "            W_LEV_AVG_lag_14  W_LEV_AVG_lag_15  W_LEV_AVG_lag_16  \\\n",
       "DATE                                                               \n",
       "2016-08-09         -0.416648         -0.262940         -0.347915   \n",
       "2016-08-10         -0.335149         -0.416648         -0.262940   \n",
       "2016-08-11         -0.288399         -0.335149         -0.416648   \n",
       "2016-08-12         -0.343085         -0.288399         -0.335149   \n",
       "2016-08-13         -0.347185         -0.343085         -0.288399   \n",
       "...                      ...               ...               ...   \n",
       "2023-12-27          0.280124          0.270866          0.200095   \n",
       "2023-12-28          0.315138          0.280124          0.270866   \n",
       "2023-12-29          0.264506          0.315138          0.280124   \n",
       "2023-12-30          0.255712          0.264506          0.315138   \n",
       "2023-12-31          0.405360          0.255712          0.264506   \n",
       "\n",
       "            W_LEV_AVG_lag_17  W_LEV_AVG_lag_18  W_LEV_AVG  prediction_label  \n",
       "DATE                                                                         \n",
       "2016-08-09         -0.269145         -0.333580  -0.404411         -0.417766  \n",
       "2016-08-10         -0.347915         -0.269145  -0.501238         -0.414057  \n",
       "2016-08-11         -0.262940         -0.347915  -0.575842         -0.487823  \n",
       "2016-08-12         -0.416648         -0.262940  -0.452125         -0.553355  \n",
       "2016-08-13         -0.335149         -0.416648  -0.503794         -0.459493  \n",
       "...                      ...               ...        ...               ...  \n",
       "2023-12-27          0.182337          0.212726   0.479415          0.629889  \n",
       "2023-12-28          0.200095          0.182337   0.411685          0.391010  \n",
       "2023-12-29          0.270866          0.200095   0.377428          0.369154  \n",
       "2023-12-30          0.280124          0.270866   0.399299          0.349285  \n",
       "2023-12-31          0.315138          0.280124   0.287383          0.371205  \n",
       "\n",
       "[2026 rows x 27 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_d = df_test.resample(\"D\").mean()\n",
    "df_test_d.dropna(inplace=True)\n",
    "# Create lag features for the past 14 days\n",
    "for lag in range(1, 19):  # Lags from 1 to 14 days\n",
    "    df_test_d[f'W_LEV_AVG_lag_{lag}'] = df_test_d['W_LEV_AVG'].shift(lag)\n",
    "df_test_d.dropna(inplace=True)\n",
    "test_prediction_d = exp.predict_model(best_model, data=df_test_d)\n",
    "test_prediction_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "วัดความแม่นยำโดยใช้ MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1985a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1985a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_1985a_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_1985a_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_1985a_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_1985a_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_1985a_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_1985a_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1985a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1985a_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_1985a_row0_col1\" class=\"data row0 col1\" >0.0132</td>\n",
       "      <td id=\"T_1985a_row0_col2\" class=\"data row0 col2\" >0.0003</td>\n",
       "      <td id=\"T_1985a_row0_col3\" class=\"data row0 col3\" >0.0162</td>\n",
       "      <td id=\"T_1985a_row0_col4\" class=\"data row0 col4\" >0.9995</td>\n",
       "      <td id=\"T_1985a_row0_col5\" class=\"data row0 col5\" >0.0101</td>\n",
       "      <td id=\"T_1985a_row0_col6\" class=\"data row0 col6\" >0.0609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a93cdf410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9995\n",
      "Mean Absolute Error (MAE): 0.0132\n",
      "Root Mean Squared Error (RMSE): 0.0162\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#compare_data 30 index\n",
    "from pycaret.regression import *\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = exp.predict_model(best_model, data=compare_data)  # Last 7 known values\n",
    "\n",
    "# Extract actual values and predicted values\n",
    "y_true = compare_data[\"W_LEV_AVG\"].values\n",
    "y_pred = test_predictions[\"prediction_label\"].values  # \"prediction_label\" contains predictions\n",
    "\n",
    "# Calculate Regression Metrics\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Calculate Accuracy as (1 - (MAE / mean_actual)) * 100\n",
    "mean_actual = np.mean(y_true)  # Mean of actual values\n",
    "accuracy = max(0, min(100, (1 - (mae / mean_actual)) * 100))  # Accuracy in percentage\n",
    "\n",
    "# Print Results\n",
    "print(f\"R² Score: {r2:.4f}\")  # Closer to 1 is better\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")  # Lower is better\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")  # Lower is better\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")  # Accuracy percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ad59b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ad59b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ad59b_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_ad59b_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_ad59b_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_ad59b_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_ad59b_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_ad59b_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ad59b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ad59b_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_ad59b_row0_col1\" class=\"data row0 col1\" >0.0153</td>\n",
       "      <td id=\"T_ad59b_row0_col2\" class=\"data row0 col2\" >0.0009</td>\n",
       "      <td id=\"T_ad59b_row0_col3\" class=\"data row0 col3\" >0.0308</td>\n",
       "      <td id=\"T_ad59b_row0_col4\" class=\"data row0 col4\" >0.9984</td>\n",
       "      <td id=\"T_ad59b_row0_col5\" class=\"data row0 col5\" >0.0176</td>\n",
       "      <td id=\"T_ad59b_row0_col6\" class=\"data row0 col6\" >0.1002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a93fd8310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9984\n",
      "Mean Absolute Error (MAE): 0.0153\n",
      "Root Mean Squared Error (RMSE): 0.0308\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Train Data \n",
    "from pycaret.regression import *\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = exp.predict_model(best_model, data=df)  # Last 7 known values\n",
    "\n",
    "# Extract actual values and predicted values\n",
    "y_true = df[\"W_LEV_AVG\"].values\n",
    "y_pred = test_predictions[\"prediction_label\"].values  # \"prediction_label\" contains predictions\n",
    "\n",
    "# Calculate Regression Metrics\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Calculate Accuracy as (1 - (MAE / mean_actual)) * 100\n",
    "mean_actual = np.mean(y_true)  # Mean of actual values\n",
    "accuracy = max(0, min(100, (1 - (mae / mean_actual)) * 100))  # Accuracy in percentage\n",
    "\n",
    "# Print Results\n",
    "print(f\"R² Score: {r2:.4f}\")  # Closer to 1 is better\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")  # Lower is better\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")  # Lower is better\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")  # Accuracy percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bf77c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bf77c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bf77c_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_bf77c_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_bf77c_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_bf77c_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_bf77c_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_bf77c_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bf77c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bf77c_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_bf77c_row0_col1\" class=\"data row0 col1\" >0.0288</td>\n",
       "      <td id=\"T_bf77c_row0_col2\" class=\"data row0 col2\" >0.0012</td>\n",
       "      <td id=\"T_bf77c_row0_col3\" class=\"data row0 col3\" >0.0346</td>\n",
       "      <td id=\"T_bf77c_row0_col4\" class=\"data row0 col4\" >0.9949</td>\n",
       "      <td id=\"T_bf77c_row0_col5\" class=\"data row0 col5\" >0.0241</td>\n",
       "      <td id=\"T_bf77c_row0_col6\" class=\"data row0 col6\" >0.3752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a88a73250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9949\n",
      "Mean Absolute Error (MAE): 0.0288\n",
      "Root Mean Squared Error (RMSE): 0.0346\n",
      "Accuracy: 35.75%\n"
     ]
    }
   ],
   "source": [
    "# Other file test data\n",
    "from pycaret.regression import *\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = exp.predict_model(best_model, data=df_test)  # Last 7 known values\n",
    "\n",
    "# Extract actual values and predicted values\n",
    "y_true = df_test[\"W_LEV_AVG\"].values\n",
    "y_pred = test_predictions[\"prediction_label\"].values  # \"prediction_label\" contains predictions\n",
    "\n",
    "# Calculate Regression Metrics\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Calculate Accuracy as (1 - (MAE / mean_actual)) * 100\n",
    "mean_actual = np.mean(y_true)  # Mean of actual values\n",
    "accuracy = max(0, min(100, (1 - (mae / mean_actual)) * 100))  # Accuracy in percentage\n",
    "\n",
    "# Print Results\n",
    "print(f\"R² Score: {r2:.4f}\")  # Closer to 1 is better\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")  # Lower is better\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")  # Lower is better\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")  # Accuracy percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "วัดความแม่นยำโดยใช้ MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b750c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b750c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b750c_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_b750c_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_b750c_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_b750c_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_b750c_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_b750c_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b750c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b750c_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_b750c_row0_col1\" class=\"data row0 col1\" >0.0132</td>\n",
       "      <td id=\"T_b750c_row0_col2\" class=\"data row0 col2\" >0.0003</td>\n",
       "      <td id=\"T_b750c_row0_col3\" class=\"data row0 col3\" >0.0162</td>\n",
       "      <td id=\"T_b750c_row0_col4\" class=\"data row0 col4\" >0.9995</td>\n",
       "      <td id=\"T_b750c_row0_col5\" class=\"data row0 col5\" >0.0101</td>\n",
       "      <td id=\"T_b750c_row0_col6\" class=\"data row0 col6\" >0.0609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17ae0c793d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9995\n",
      "Mean Absolute Error (MAE): 0.0132\n",
      "Root Mean Squared Error (RMSE): 0.0162\n",
      "Mean Absolute Percentage Error (MAPE): 6.09%\n",
      "Accuracy: 93.91%\n"
     ]
    }
   ],
   "source": [
    "#compare_data 30 index\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = exp.predict_model(best_model, data=compare_data)\n",
    "\n",
    "# Extract actual values and predicted values\n",
    "y_true = compare_data[\"W_LEV_AVG\"].values\n",
    "y_pred = test_predictions[\"prediction_label\"].values\n",
    "\n",
    "# Filter out zeros from y_true to avoid division by zero in MAPE calculation\n",
    "non_zero_indices = y_true != 0\n",
    "y_true_non_zero = y_true[non_zero_indices]\n",
    "y_pred_non_zero = y_pred[non_zero_indices]\n",
    "\n",
    "# Calculate Regression Metrics\n",
    "r2 = r2_score(y_true_non_zero, y_pred_non_zero)\n",
    "mae = mean_absolute_error(y_true_non_zero, y_pred_non_zero)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_non_zero, y_pred_non_zero))\n",
    "\n",
    "# Calculate MAPE and Accuracy for non-zero values\n",
    "mape = np.mean(np.abs((y_true_non_zero - y_pred_non_zero) / y_true_non_zero)) * 100\n",
    "accuracy = 100 - mape  # Convert to Accuracy %\n",
    "\n",
    "# Print Results\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_21599\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_21599_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_21599_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_21599_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_21599_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_21599_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_21599_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_21599_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_21599_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_21599_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_21599_row0_col1\" class=\"data row0 col1\" >0.0153</td>\n",
       "      <td id=\"T_21599_row0_col2\" class=\"data row0 col2\" >0.0009</td>\n",
       "      <td id=\"T_21599_row0_col3\" class=\"data row0 col3\" >0.0308</td>\n",
       "      <td id=\"T_21599_row0_col4\" class=\"data row0 col4\" >0.9984</td>\n",
       "      <td id=\"T_21599_row0_col5\" class=\"data row0 col5\" >0.0176</td>\n",
       "      <td id=\"T_21599_row0_col6\" class=\"data row0 col6\" >0.1002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17ae0d74990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9985\n",
      "Mean Absolute Error (MAE): 0.0153\n",
      "Root Mean Squared Error (RMSE): 0.0302\n",
      "Mean Absolute Percentage Error (MAPE): 10.02%\n",
      "Accuracy: 89.98%\n"
     ]
    }
   ],
   "source": [
    "# Train Data \n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = exp.predict_model(best_model, data=df)\n",
    "\n",
    "# Extract actual values and predicted values\n",
    "y_true = df[\"W_LEV_AVG\"].values\n",
    "y_pred = test_predictions[\"prediction_label\"].values\n",
    "\n",
    "# Filter out zeros from y_true to avoid division by zero in MAPE calculation\n",
    "non_zero_indices = y_true != 0\n",
    "y_true_non_zero = y_true[non_zero_indices]\n",
    "y_pred_non_zero = y_pred[non_zero_indices]\n",
    "\n",
    "# Calculate Regression Metrics\n",
    "r2 = r2_score(y_true_non_zero, y_pred_non_zero)\n",
    "mae = mean_absolute_error(y_true_non_zero, y_pred_non_zero)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_non_zero, y_pred_non_zero))\n",
    "\n",
    "# Calculate MAPE and Accuracy for non-zero values\n",
    "mape = np.mean(np.abs((y_true_non_zero - y_pred_non_zero) / y_true_non_zero)) * 100\n",
    "accuracy = 100 - mape  # Convert to Accuracy %\n",
    "\n",
    "# Print Results\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f8652\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f8652_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f8652_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_f8652_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_f8652_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_f8652_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_f8652_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_f8652_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f8652_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f8652_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_f8652_row0_col1\" class=\"data row0 col1\" >0.0288</td>\n",
       "      <td id=\"T_f8652_row0_col2\" class=\"data row0 col2\" >0.0012</td>\n",
       "      <td id=\"T_f8652_row0_col3\" class=\"data row0 col3\" >0.0346</td>\n",
       "      <td id=\"T_f8652_row0_col4\" class=\"data row0 col4\" >0.9949</td>\n",
       "      <td id=\"T_f8652_row0_col5\" class=\"data row0 col5\" >0.0241</td>\n",
       "      <td id=\"T_f8652_row0_col6\" class=\"data row0 col6\" >0.3752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a98b724d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9949\n",
      "Mean Absolute Error (MAE): 0.0288\n",
      "Root Mean Squared Error (RMSE): 0.0346\n",
      "Mean Absolute Percentage Error (MAPE): 37.52%\n",
      "Accuracy: 62.48%\n"
     ]
    }
   ],
   "source": [
    "# Other file test data\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = exp.predict_model(best_model, data=df_test)\n",
    "\n",
    "# Extract actual values and predicted values\n",
    "y_true = df_test[\"W_LEV_AVG\"].values\n",
    "y_pred = test_predictions[\"prediction_label\"].values\n",
    "\n",
    "# Filter out zeros from y_true to avoid division by zero in MAPE calculation\n",
    "non_zero_indices = y_true != 0\n",
    "y_true_non_zero = y_true[non_zero_indices]\n",
    "y_pred_non_zero = y_pred[non_zero_indices]\n",
    "\n",
    "# Calculate Regression Metrics\n",
    "r2 = r2_score(y_true_non_zero, y_pred_non_zero)\n",
    "mae = mean_absolute_error(y_true_non_zero, y_pred_non_zero)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_non_zero, y_pred_non_zero))\n",
    "\n",
    "# Calculate MAPE and Accuracy for non-zero values\n",
    "mape = np.mean(np.abs((y_true_non_zero - y_pred_non_zero) / y_true_non_zero)) * 100\n",
    "accuracy = 100 - mape  # Convert to Accuracy %\n",
    "\n",
    "# Print Results\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ลองทำนายอนาคต"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ข้อมูลรายวัน:\n",
      "     date_only W_LEV_AVG  moon_phase\n",
      "0   2023-12-28 -0.213389   96.000000\n",
      "1   2023-12-29 -0.212059   96.000000\n",
      "2   2023-12-29 -0.212059   96.000000\n",
      "3   2023-12-29 -0.212059   95.700000\n",
      "4   2023-12-29 -0.212059   95.000000\n",
      "..         ...       ...         ...\n",
      "68  2023-12-31 -0.211564   79.416667\n",
      "69  2023-12-31 -0.211564   79.000000\n",
      "70  2023-12-31 -0.211564   79.000000\n",
      "71  2023-12-31 -0.211564   78.550000\n",
      "72  2023-12-31 -0.211564   78.000000\n",
      "\n",
      "[73 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ephem\n",
    "# สร้าง DataFrame สำหรับอนาคต\n",
    "future_dates = pd.date_range(df.index.max(), periods=3*24*60, freq=\"T\")\n",
    "future_df = pd.DataFrame(index=future_dates)  # ใช้เป็น index\n",
    "future_df[\"DATE\"] = future_df.index  # เพิ่มคอลัมน์ DATE\n",
    "# คำนวณ moon phase\n",
    "def get_moon_phase(dt):\n",
    "    return round(ephem.Moon(dt).phase)\n",
    "future_df[\"moon_phase\"] = future_df[\"DATE\"].apply(get_moon_phase)\n",
    "# เพิ่ม full_moon_days (ขึ้น 15 ค่ำ) และ dark_moon_days (แรม 15 ค่ำ)\n",
    "future_df[\"full_moon_days\"] = (future_df[\"moon_phase\"] == 15).astype(int)\n",
    "future_df[\"dark_moon_days\"] = (future_df[\"moon_phase\"] == 29).astype(int)\n",
    "# ดึงค่าเวลาออกมาเป็น feature\n",
    "future_df[\"dayofweek\"] = future_df[\"DATE\"].dt.dayofweek\n",
    "future_df[\"month\"] = future_df[\"DATE\"].dt.month\n",
    "future_df[\"day\"] = future_df[\"DATE\"].dt.day\n",
    "future_df[\"hour\"] = future_df[\"DATE\"].dt.hour\n",
    "# สร้างค่าเริ่มต้นของ lag\n",
    "lag_columns = [f\"W_LEV_AVG_lag_{i}\" for i in range(1, 19)]\n",
    "for col in lag_columns:\n",
    "    future_df[col] = None  # กำหนดค่าเริ่มต้นเป็น None หรือค่าเฉลี่ย\n",
    "# ถ้าไม่มีข้อมูลจริงล่าสุด ใช้ค่าเฉลี่ยของ df\n",
    "lag_mean_values = df[lag_columns].mean()\n",
    "for col in lag_columns:\n",
    "    future_df[col] = lag_mean_values[col]  # ใช้ค่าเฉลี่ยของ lag จากข้อมูลเก่า\n",
    "# สร้างคอลัมน์ W_LEV_AVG เพื่อเก็บค่าที่ทำนาย\n",
    "future_df['W_LEV_AVG'] = None\n",
    "# กำหนด features ที่ใช้ในการทำนาย (ปรับตามที่ best_model ของคุณต้องการ)\n",
    "model_features = ['moon_phase', 'full_moon_days', 'dark_moon_days', 'dayofweek', \n",
    "                  'month', 'day', 'hour'] + lag_columns\n",
    "# ทำนาย step-by-step และอัปเดต lag feature \n",
    "for i in range(len(future_df)):\n",
    "    # เตรียมข้อมูลสำหรับการทำนาย\n",
    "    current_idx = future_df.index[i]\n",
    "    \n",
    "    # ดึงข้อมูล features สำหรับการทำนาย\n",
    "    X_pred = future_df.loc[current_idx, model_features].values.reshape(1, -1)\n",
    "    \n",
    "    # ทำนายด้วย best_model\n",
    "    predicted_value = best_model.predict(X_pred)[0]\n",
    "    \n",
    "    # บันทึกค่าที่ทำนายได้\n",
    "    future_df.at[current_idx, 'W_LEV_AVG'] = predicted_value\n",
    "    \n",
    "    # อัปเดต lag features สำหรับข้อมูลถัดไป (ถ้าไม่ใช่ข้อมูลสุดท้าย)\n",
    "    if i < len(future_df) - 1:\n",
    "        next_idx = future_df.index[i+1]\n",
    "        \n",
    "        # อัปเดต lag_1 ด้วยค่าที่ทำนายได้ล่าสุด\n",
    "        future_df.at[next_idx, 'W_LEV_AVG_lag_1'] = predicted_value\n",
    "        \n",
    "        # shift ค่า lag ที่เหลือ\n",
    "        for j in range(18, 1, -1):\n",
    "            future_df.at[next_idx, f\"W_LEV_AVG_lag_{j}\"] = future_df.at[current_idx, f\"W_LEV_AVG_lag_{j-1}\"]\n",
    "\n",
    "# #แสดงผลลัพธ์รายนาที\n",
    "# print(\"ข้อมูลรายนาที:\")\n",
    "# print(future_df[['DATE', 'W_LEV_AVG'] + lag_columns].head())\n",
    "\n",
    "# สร้างข้อมูลรายวันโดยใช้ resample\n",
    "daily_future_df = future_df.resample('H', on='DATE').mean()\n",
    "\n",
    "# รีเซ็ต index เพื่อให้วันที่กลายเป็นคอลัมน์\n",
    "daily_future_df = daily_future_df.reset_index()\n",
    "\n",
    "# เพิ่มคอลัมน์วันที่เพื่อความชัดเจน\n",
    "daily_future_df['date_only'] = daily_future_df['DATE'].dt.date\n",
    "\n",
    "# เลือกเฉพาะคอลัมน์ที่สำคัญ\n",
    "selected_columns = ['date_only', 'W_LEV_AVG', 'moon_phase']\n",
    "\n",
    "# แสดงผลลัพธ์รายวัน\n",
    "print(\"\\nข้อมูลรายวัน:\")\n",
    "print(daily_future_df[selected_columns])\n",
    "\n",
    "# บันทึกเป็นไฟล์ถ้าต้องการ\n",
    "# daily_future_df.to_csv('daily_water_level_forecast.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
